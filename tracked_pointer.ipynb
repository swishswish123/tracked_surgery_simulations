{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOEy6C1K/jwjv7DGCiV6QrU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swishswish123/tracked_surgery_simulations/blob/main/tracked_pointer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) TRACKED POINTER SIMULATION\n",
        "\n",
        "The current state of the art for pituitary surgery uses a tracked pointer, registered to a pre-operative MR scan for orientation of surrounding anatomy. This notebook explores what the expected level of accuracy might be."
      ],
      "metadata": {
        "id": "ClVWXI9rJHE_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## imports and utility functions"
      ],
      "metadata": {
        "id": "RQ7Qv8i7tJgB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVxom-fAIbK5",
        "outputId": "31fe5a08-a460-4147-fbe1-2fa75120129e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'repo'...\n",
            "remote: Enumerating objects: 59, done.\u001b[K\n",
            "remote: Counting objects: 100% (59/59), done.\u001b[K\n",
            "remote: Compressing objects: 100% (56/56), done.\u001b[K\n",
            "remote: Total 59 (delta 27), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (59/59), 1.10 MiB | 3.53 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "# github repo which contains all the images\n",
        "!git clone https://github.com/swishswish123/tracked_surgery_simulations.git repo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install necessary packages\n",
        "!pip install scikit-surgerycore"
      ],
      "metadata": {
        "id": "Io2ussU7h-lb",
        "outputId": "fdd786bc-edfc-40bf-f3db-1d7c0474958d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-surgerycore\n",
            "  Downloading scikit-surgerycore-0.6.10.tar.gz (39 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from scikit-surgerycore) (1.22.4)\n",
            "Building wheels for collected packages: scikit-surgerycore\n",
            "  Building wheel for scikit-surgerycore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surgerycore: filename=scikit_surgerycore-0.6.10-py2.py3-none-any.whl size=23594 sha256=186df7c2d6890b19588942fa51676bef199391090255916b46ac30538300cf63\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/41/e0/a9243058cb461a809cd19756422265b39cfc3c67b73589ad53\n",
            "Successfully built scikit-surgerycore\n",
            "Installing collected packages: scikit-surgerycore\n",
            "Successfully installed scikit-surgerycore-0.6.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing packages\n",
        "from IPython.display import Image\n",
        "import numpy as np\n",
        "import sksurgerycore.transforms.matrix as stm\n",
        "import sksurgerycore.transforms.matrix as mu\n",
        "import cv2\n",
        "import math\n",
        "import sksurgerycore.algorithms.procrustes as pro\n",
        "from scipy.spatial.transform import Rotation as spr\n",
        "import copy\n",
        "import random"
      ],
      "metadata": {
        "id": "yY5bRaLsjCDQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def extrinsic_matrix_to_vecs(matrix):\n",
        "    \"\"\"\n",
        "    extract_rigid_body_parameters(matrix)\n",
        "    extracts parameters from transformation matrix\n",
        "\n",
        "    Args:\n",
        "        matrix: 4x4 transformation matrix\n",
        "\n",
        "    Returns:\n",
        "        list of rigid body parameters [tx, ty, tz, rx, ry, rz]\n",
        "\n",
        "    \"\"\"\n",
        "    t = matrix[0:3, 3]\n",
        "    r = matrix[0:3, 0:3]\n",
        "    rot = spr.from_matrix(r)\n",
        "    euler = rot.as_euler('xyz', degrees=True)\n",
        "    return [t[0], t[1], t[2], euler[0], euler[1], euler[2]]\n",
        "\n",
        "def extrinsic_vecs_to_matrix(params):\n",
        "    \"\"\"\n",
        "    rigid_body_parameters_to_matrix(params)\n",
        "    converts a list of rigid body parameters to transformation matrix\n",
        "\n",
        "    Args:\n",
        "        params: list of rigid body parameters [tx, ty, tz, rx, ry, rz]\n",
        "\n",
        "    Returns:\n",
        "        4x4 transformation matrix of these parameters\n",
        "\n",
        "    \"\"\"\n",
        "    matrix = np.eye(4)\n",
        "    \n",
        "    matrix[0][3] = params[0]\n",
        "    matrix[1][3] = params[1]\n",
        "    matrix[2][3] = params[2]\n",
        "\n",
        "    r = (spr.from_euler('xyz', [params[3], params[4], params[5]], degrees=True)).as_matrix()\n",
        "    matrix[0:3, 0:3] = r\n",
        "    return matrix\n",
        "\n"
      ],
      "metadata": {
        "id": "Z-_Kp14Be9Ix"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def multiply_points_by_matrix(matrix_4x4, matrix_of_points, do_transpose):\n",
        "    \"\"\"\n",
        "    Multiplies all points by the same matrix.\n",
        "\n",
        "    :param matrix_4x4: Numpy ndarray, 4x4, containing homogenous, rigid transformation\n",
        "    :param matrix_of_points: Numpy ndarray, 4xN, containing N points as 4D homogeneous column vectors.\n",
        "    :param do_transpose: if true, we also transpose\n",
        "    \"\"\"\n",
        "    input_matrix = matrix_of_points\n",
        "\n",
        "    if do_transpose:\n",
        "        input_matrix = np.transpose(matrix_of_points)\n",
        "\n",
        "    result = np.matmul(matrix_4x4, input_matrix)\n",
        "\n",
        "    if do_transpose:\n",
        "        result = np.transpose(result)\n",
        "\n",
        "    return result\n",
        "\n",
        "def multiply_points_by_transform(D3_hom, T):\n",
        "    \"\"\"\n",
        "    Applies a 4x4 transformation matrix to a set of 3D points.\n",
        "\n",
        "    Args:\n",
        "        D3_points (numpy.ndarray): Array of 3D points with shape (N, 3).\n",
        "        T (numpy.ndarray): 4x4 transformation matrix.\n",
        "\n",
        "    Returns:\n",
        "        (numpy.ndarray) Array of transformed 3D points with shape (N, 3).\n",
        "    \"\"\"\n",
        "    #D3_hom = cv2.convertPointsToHomogeneous(D3_points).squeeze()\n",
        "    D3_transformed_points_hom = T @ D3_hom.T\n",
        "    #D3_transformed_points_hom = D3_transformed_points_hom.reshape(4, -1)\n",
        "    #D3_transformed = cv2.convertPointsFromHomogeneous(D3_transformed_points_hom.T).squeeze()\n",
        "\n",
        "    return D3_transformed_points_hom.T"
      ],
      "metadata": {
        "id": "KPzJhEUwfDEO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "se6c4U_LywSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Background, System Layout, goal and assumptions\n",
        "\n",
        "The following diagram shows the layout of the navigation system and the different components involved in the surgery when using a pointer. "
      ],
      "metadata": {
        "id": "_bd4tC5lvDmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image(filename=\"./repo/assets/pointer_setup.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "_kprisp7xKBf",
        "outputId": "f8a9404b-ee12-4332-fa7a-dc8dd53af82d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-f30e7a58899d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./repo/assets/pointer_setup.pdf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata)\u001b[0m\n\u001b[1;32m   1221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ACCEPTABLE_EMBEDDINGS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot embed the '%s' image format\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mimetype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_MIMETYPES\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot embed the 'pdf' image format"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### A bit of maths background:\n",
        "To convert between different coordinate systems, we can use a mathematical transform, defined as ${}^{B}T_{A}$. This maps a point from the coordinate system $A$ to the coordinate system $B$. \n",
        "\n",
        "${}^{B}T_{A}$ can be defined as a (4x4) matrix. Since we assume the transformations to be rigid, this matrix can only be composed of rotations and translations.\n",
        "\n",
        "${}^{B}T_{A} = \n",
        "\\begin{bmatrix}\n",
        "R & T \\\\\n",
        "0 & 1\n",
        "\\end{bmatrix}$\n",
        "\n",
        "Where R is a (3x3) sub-matrix of ${}^{B}T_{A}$, represents the rotation component of the transform. It defines how the axes of the $A$ coordinate system should be rotated to align with the axes of the $B$ coordinate system. The translation component, denoted as $T$ (3x1), represents the offset between the origins of the $A$ and $B$ coordinate systems.\n",
        "\n",
        "Now by applying ${}^{B}T_{A}$ to a point in the $A$ coordinate system, we can transform the point to its corresponding position in the $B$ coordinate system. \n",
        "\n",
        "### Combining transforms\n",
        "Different transforms can be combined to create a transform from one coordinate system to another. Suppose we have three coordinate systems, $A$, $B$, and $C$. We have transformations ${}^{B}T_{A}$ which map points from coordinate system $A$ to $B$ and ${}^{C}T_{B}$ which maps from $B$ to $C$. We can use these transformations to create a transform ${}^{C}T_{A}$, which maps points from coordinate system $A$ to $C$. This composed transform can be obtained by simply multiplying the other two in the correct order:\n",
        "\n",
        "${}^{C}T_{A}$ = ${}^{C}T_{B}$ Â· ${}^{B}T_{A}$\n",
        "\n",
        "Note that the combination starts on the right and ends on the left- we start at coordinate system $A$ and convert it to $B$ with ${}^{B}T_{A}$ on the right and then we move towards the left converting $B$ to $C$- ${}^{C}T_{B}$.\n",
        "\n",
        "${}^{C}T_{A}$ can now be used to convert any point from coordinate system $A$ to coordinate system $C$.\n",
        "\n"
      ],
      "metadata": {
        "id": "A_DEYtwN1qP-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Goal\n",
        "\n",
        "Going back to our problem, the goal is to be able to match the coordinate system of the pointer's tip to the MRI so that wherever we put the pointer's tip, this location can be displayed on the MRI.\n",
        "\n",
        "What we want to achieve is obtain a transform\n",
        "from the pointer's tip to the MRI coordinate system.\n",
        "\n",
        "X<sub>MRI</sub> = T X<sub>PntTip</sub>\n",
        "\n",
        "We cannot obtain a direct transformation with our setup, but we can build this transformation out of the following transformations:\n",
        "\n",
        "T = <sup>MRI</sup>T<sub>PatRef</sub> * \n",
        "    <sup>PatRef</sup>T<sub>Cam</sub>  * \n",
        "    <sup>Cam</sup>T<sub>PntRef</sub> * \n",
        "    <sup>PntRef</sup>T<sub>PntTip</sub>\n",
        "\n",
        "Note on notation used:\n",
        "As in the diagram, Pnt stands for pointer, Ref stands for reference, Cam stands for the infrared camera and Pat stands for patient. \n",
        "\n",
        "In the following sections we will go step by step composing these transforms and finally using them to transform a point from pointer tip (PntTip) coordinates to MRI coordinates.\n",
        "\n",
        "Below is a visual representation of the pointer setup with all the transforms:\n"
      ],
      "metadata": {
        "id": "uTkWNHxx-2Bu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image(filename=\"./repo/assets/pointer_setup_transforms.png\")"
      ],
      "metadata": {
        "id": "IRoROBWg-0by",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "outputId": "3df4f3d4-da0e-495c-fbfc-b5c6f5ee6ffd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-0dd0b8a5ec36>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./repo/assets/pointer_setup_transforms.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata)\u001b[0m\n\u001b[1;32m   1229\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretina\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretina\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1230\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconfined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munconfined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1231\u001b[0;31m         super(Image, self).__init__(data=data, url=url, filename=filename, \n\u001b[0m\u001b[1;32m   1232\u001b[0m                 metadata=metadata)\n\u001b[1;32m   1233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1261\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1263\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1264\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretina\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retina_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_flags\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './repo/assets/pointer_setup_transforms.png'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Assumptions\n",
        "\n",
        "1. tumour, patient reference, pointer reference are all aligned in z direction (have same z coordinate) and are facing the camera straight on so that the distance is $D$.\n",
        "\n",
        "2. Patient reference is at a set distance $Y_t$ from the tumour but aligned in the X direction.\n",
        "\n",
        "3. Pointer is touching the tumour, so the pointer and tumour have the same coordinates.\n",
        "\n",
        "4. Length of pointer is known ($P$)\n",
        "\n",
        "5. Angle of pointer is known ($ðœƒ$)\n",
        "\n",
        "6. All transformations assumed to be rigid\n",
        "\n",
        "Below is a visual representation of the sagittal and transverse views with all assumptions.\n"
      ],
      "metadata": {
        "id": "RJk4josoAuV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image(filename=\"./repo/assets/pointer_setup_assumptions.png\")"
      ],
      "metadata": {
        "id": "0dbJQXPT0ZkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assumptions- configurable parameters\n",
        "\n",
        "# ALL MEASUREMENTS IN MM\n",
        "\n",
        "# P - length from tip of pointer to reference of pointer\n",
        "POINTER_LENGTH = 140  # reference NDI\n",
        "\n",
        "# D - z distance from camera to plane where everything is located\n",
        "DISTANCE_FROM_CAM = 2000  # since the camera and patient reference are aligned in the x and y directions, only distance is in z\n",
        "\n",
        "# ðœƒ - angle of pointer\n",
        "POINTER_ANGLE = 45\n",
        "\n",
        "# Yt - distances from tumour to patient reference\n",
        "TUMOUR_PARTEF = 300\n",
        "\n",
        "# NDI quotes 0.25mm for Polaris Spectra, some papers estimate it at 0.17mm\n",
        "# TYPICAL_TRACKING_SIGMA = 0.25\n",
        "\n",
        "# for simulation reproducibility\n",
        "NUMBER_SAMPLES = 9000\n",
        "\n",
        "# for sufrace registration initial misalignment\n",
        "X_T = 100  # head length (about 20cm)\n",
        "Y_T = 130  # menton to top of head (about 25cm)\n",
        "Z_T = 80  # head bredth (about 15cm)\n",
        "\n",
        "END_SIGMA = 0.5\n",
        "SIGMA_STEP = 0.01\n"
      ],
      "metadata": {
        "id": "9aS9WUH71cOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining some functions\n",
        "\n",
        "In order to obtain the transforms, we also need to define the reference of the different coordinate systems.\n",
        "\n",
        "A reference is essentially a unique grouping of reflective markers, attached to a tool which defines a local coordinate system. The markers' location can be determined as they are reflective and therefore the infrared camera can locate them in space at any given point if they are within the camera's working range.\n",
        "\n",
        "Below you can see the reference systems used for the patient and the pointer:"
      ],
      "metadata": {
        "id": "pZAHv33lF0_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pointer reference\n",
        "Image('./repo/assets/pointref_geometry.png')\n"
      ],
      "metadata": {
        "id": "r5_sEAdVd1go"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# patient reference\n",
        "Image('./repo/assets/patref_geometry.png')\n"
      ],
      "metadata": {
        "id": "drrTxjkyd291"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def create_pat_ref():\n",
        "    \"\"\"\n",
        "    Create reference coordinates of a marker pattern in a numpy matrix.\n",
        "\n",
        "    This function creates a numpy matrix containing the reference coordinates of a marker pattern used for\n",
        "    pose estimation. The marker pattern consists of four markers labeled A, B, C and D. The reference coordinates\n",
        "    of each marker point are defined in a right-handed reference frame as follows:\n",
        "\n",
        "        Marker A: (0, 0, 0)\n",
        "        Marker B: (41.02, 0, 28.59)\n",
        "        Marker C: (88.00, 0, 0)\n",
        "        Marker D: (40.45, 0, -44.32)\n",
        "\n",
        "    The function returns a 4x4 numpy matrix containing the homogenous coordinates of each marker point, with the\n",
        "    last element of each row set to 1.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: A 4x4 numpy matrix containing reference coordinates of a marker pattern. Each row represents a\n",
        "        marker point in homogenous coordinates.\n",
        "    \"\"\"\n",
        "\n",
        "    # Encoding the reference marker points into a numpy matrix\n",
        "    pat_ref = np.zeros((4, 4))\n",
        "    # marker A (0) -> (0,0,0)\n",
        "\n",
        "    # marker B (1) -> (41.02 ,0,28.59)\n",
        "    pat_ref[1][0] = 41.02  # x\n",
        "    pat_ref[1][2] = 28.59  # z\n",
        "\n",
        "    # marker C (2) -> C = (88.00 ,0, 0)\n",
        "    pat_ref[2][0] = 88  # x\n",
        "\n",
        "    # marker D (3) -> (40.45,0,-44.32)\n",
        "    pat_ref[3][0] = 40.45  # x\n",
        "    pat_ref[3][2] = -44.32  # z\n",
        "\n",
        "    # adding 1 to last row to make coordinates homogenous\n",
        "    pat_ref[0][3] = 1.0\n",
        "    pat_ref[1][3] = 1.0\n",
        "    pat_ref[2][3] = 1.0\n",
        "    pat_ref[3][3] = 1.0\n",
        "    return pat_ref\n",
        "\n",
        "\n",
        "def create_pnt_ref():\n",
        "    \"\"\"\n",
        "    Creates a numpy matrix representing the pointer reference coordinates.\n",
        "\n",
        "    Returns:\n",
        "    pnt_ref (numpy matrix): A 4x4 numpy matrix containing the pointer reference coordinates\n",
        "                            as row vectors in homogenous coordinates. The four rows represent\n",
        "                            the markers A, B, C, and D in that order.\n",
        "    \"\"\"\n",
        "    # Creating pointer reference (from datasheet). Using homogenous (4 numbers, x,y,z,1) as row vectors.\n",
        "    pnt_ref = np.zeros((4, 4))\n",
        "\n",
        "    # marker A (0) -> 0,0,0\n",
        "\n",
        "    # marker B (1) -> 0,50,0\n",
        "    pnt_ref[1][1] = 50  # y\n",
        "\n",
        "    # marker c (2) -> 25,100,0\n",
        "    pnt_ref[2][0] = 25  # x\n",
        "    pnt_ref[2][1] = 100  # y\n",
        "\n",
        "    # marker d (3) -> -25, 135, 0\n",
        "    pnt_ref[3][0] = -25  # x\n",
        "    pnt_ref[3][1] = 135  # y\n",
        "\n",
        "    # adding 1 to 3rd dimension to turn to homogeneous coordinates\n",
        "    pnt_ref[0][3] = 1\n",
        "    pnt_ref[1][3] = 1\n",
        "    pnt_ref[2][3] = 1\n",
        "    pnt_ref[3][3] = 1\n",
        "\n",
        "    return pnt_ref\n",
        "\n"
      ],
      "metadata": {
        "id": "DpdD86PyF7h_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Obtaining transforms"
      ],
      "metadata": {
        "id": "_AZ14XxrFJrR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sine we are assuming the layout and relative positions of each reference marker, we are able to obtain the transformations between each coordinate system.\n",
        "\n",
        "Let's run through the simplest example- \n",
        "${}^{PntRef}T_{PntTip}$, which is the first transform we want to perform on a point in pointer tip coordinates.\n",
        "\n",
        "The only difference between the pointer tip and the pointer reference is a translation along the y direction of the pointer tip coordinate system. The value of this translation in y is the pointer's length. Note that it is a negative translation as the coordinate is now on the first marker of the reference instead of the tip.\n",
        "\n",
        "However, in our case we will initially have our values in pointer reference since the camera is tracking the markers and not the pointer tip. Therefore, we can obtain the transform ${}^{PntTip}T_{PntRef}$. This is not a problem because we can then invert this transform to obtain the transform we want:\n",
        "\n",
        "${}^{PntRef}T_{PntTip}$ = (${}^{PntTip}T_{PntRef}$)$^{-1}$\n",
        "\n",
        "A visual representation can be seen in the below diagram:"
      ],
      "metadata": {
        "id": "6mFR6bNXFVAj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image('./repo/assets/pntRef_pntTip_transform.png')"
      ],
      "metadata": {
        "id": "r7RgAmt2FmEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So first let's obtain ${}^{PntTip}T_{PntRef}$:"
      ],
      "metadata": {
        "id": "OPHrC8P3Mb46"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pointer reference in pointer reference coordinate system\n",
        "pnt_ref_marker = create_pnt_ref()  # marker coords\n",
        "\n",
        "# constructing the transformation matrix PntRef_T_PntTip with a translation in the y direction of -L\n",
        "PntTip_T_PntRef = extrinsic_vecs_to_matrix(\n",
        "        [0, POINTER_LENGTH, 0, 0, 0, 0])\n",
        "\n",
        "print('PntTip_T_PntRef')\n",
        "print(PntTip_T_PntRef)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ievzEF6TFRDA",
        "outputId": "4d19e737-0809-4fa2-f9be-10dddf73c558"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PntTip_T_PntRef\n",
            "[[  1.   0.   0.   0.]\n",
            " [  0.   1.   0. 140.]\n",
            " [  0.   0.   1.   0.]\n",
            " [  0.   0.   0.   1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "and now invert it to get ${}^{PntRef}T_{PntTip}$ :"
      ],
      "metadata": {
        "id": "H1KzI-XKMtqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PntRef_T_PntTip = np.linalg.inv(PntTip_T_PntRef)\n",
        "print('PntRef_T_PntTip')\n",
        "print(PntRef_T_PntTip)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cx1MphWM0z5",
        "outputId": "7902e5f4-2162-4a2d-bf4c-da7bb8fd7107"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PntRef_T_PntTip\n",
            "[[   1.    0.    0.    0.]\n",
            " [   0.    1.    0. -140.]\n",
            " [   0.    0.    1.    0.]\n",
            " [   0.    0.    0.    1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you can see that if we transform a point from the pointer tip coordinate system it will move by -L in the y direction. Note that coordinates are represented as homogenous coordinates to allow us to multiply by the 4x4 transform. (This basically means the coordinates are represented as [x,y,z,1]"
      ],
      "metadata": {
        "id": "oX0NdJ3pIPij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# transforming the point [0,0,0] by PntRef_T_PntTip\n",
        "pnt_ref_tip = multiply_points_by_transform(np.array([0,0,0,1]), PntRef_T_PntTip)\n",
        "print(pnt_ref_tip)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsR2gEpKJx0q",
        "outputId": "c99a7756-580f-49ed-cb26-a5ee68666f28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[   0. -140.    0.    1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also convert all the markers on the pointer reference to be represented in the pointer's tip coordinate system:"
      ],
      "metadata": {
        "id": "B0_tjc2hKVnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('original pointer reference in pointer ref coordinate system:')\n",
        "print(pnt_ref_marker)\n",
        "\n",
        "# convert to pointer tip coordinate system:\n",
        "pnt_ref_tip = multiply_points_by_transform(pnt_ref_marker, PntRef_T_PntTip)\n",
        "print('pointer reference in pointer tip coordinate system:')\n",
        "print(pnt_ref_tip)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDcstaqpIMf4",
        "outputId": "17d6e8d3-8bd9-4911-e99b-a92eb16b3297"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original pointer reference in pointer ref coordinate system:\n",
            "[[  0.   0.   0.   1.]\n",
            " [  0.  50.   0.   1.]\n",
            " [ 25. 100.   0.   1.]\n",
            " [-25. 135.   0.   1.]]\n",
            "pointer reference in pointer tip coordinate system:\n",
            "[[   0. -140.    0.    1.]\n",
            " [   0.  -90.    0.    1.]\n",
            " [  25.  -40.    0.    1.]\n",
            " [ -25.   -5.    0.    1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We perform a similar analysis to obtain the rest of the transforms. The function below generates these transformations with the given pointer length and the parameters defined in the assumptions section.\n",
        "\n",
        "Remember we want at the end a composition of all these transforms:\n",
        "\n",
        "T = <sup>MRI</sup>T<sub>PatRef</sub> * \n",
        "    <sup>PatRef</sup>T<sub>Cam</sub>  * \n",
        "    <sup>Cam</sup>T<sub>PntRef</sub> * \n",
        "    <sup>PntRef</sup>T<sub>PntTip</sub>"
      ],
      "metadata": {
        "id": "IDoaGasDHvEo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_transforms(pointer_length=100):\n",
        "    \"\"\"\n",
        "    Returns a set of coordinate transformation matrices that convert points from one reference frame to another.\n",
        "\n",
        "    Args:\n",
        "        pointer_length (float): Length of the pointer in millimeters. Default is 100.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the following eight transformation matrices:\n",
        "        - PatRef_T_MRI: A 4x4 transformation matrix that converts points from the MRI reference frame to the patient reference frame.\n",
        "        - PatRef_T_Cam: A 4x4 transformation matrix that converts points from the camera reference frame to the patient reference frame.\n",
        "        - Cam_T_PntRef: A 4x4 transformation matrix that converts points from the pointer reference frame to the camera reference frame.\n",
        "        - PntRef_T_PntTip: A 4x4 transformation matrix that converts points from the pointer tip reference frame to the pointer reference frame.\n",
        "\n",
        "        and the following numpy arrays containing the homogenous coordinates of the points in the given reference frame\n",
        "        - pnt_ref_marker:  in the pointer reference frame.\n",
        "        - pnt_ref_cam: in the camera reference frame.\n",
        "        - pat_ref_marker: in the patient reference frame.\n",
        "        - pat_ref_cam: in the camera reference frame.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # 1) obtaining PntRef_T_PntTip\n",
        "    print(f'pointer length: {pointer_length}')\n",
        "    # Creating pointer reference in the pointer reference frame.\n",
        "    pnt_ref_marker = create_pnt_ref()  # marker coords\n",
        "    # Point reference to point tip: (pointer length translation in y)\n",
        "    PntTip_T_PntRef = extrinsic_vecs_to_matrix(\n",
        "        [0, pointer_length, 0, 0, 0, 0]) # create transform of all points depending on pointer's length\n",
        "    # invert to get tip to ref:\n",
        "    PntRef_T_PntTip = np.linalg.inv(PntTip_T_PntRef)\n",
        "\n",
        "    # 2) obtaining Cam_T_PntRef\n",
        "    # Converting the marker points to the camera reference frame by applying a\n",
        "    # rotation of POINTER_ANGLE degrees about the z-axis followed by a\n",
        "    # translation of DISTANCE_FROM_CAM along the z-axis of camera.\n",
        "    rotate_about_z = extrinsic_vecs_to_matrix([0, 0, 0, 0, 0, POINTER_ANGLE])\n",
        "    translate_away_from_camera = extrinsic_vecs_to_matrix([0, 0, DISTANCE_FROM_CAM, 0, 0, 0])\n",
        "    Cam_T_PntRef = translate_away_from_camera @ rotate_about_z\n",
        "    pnt_ref_cam = multiply_points_by_transform(pnt_ref_marker, Cam_T_PntRef)\n",
        "\n",
        "    # 3) obtaining Cam_T_PatRef\n",
        "    # PatRef to Cam (add dist to cam to z plus x translation to right)\n",
        "    pat_ref_marker = create_pat_ref()\n",
        "    # translating to correct location \n",
        "    translate_along_x = extrinsic_vecs_to_matrix([TUMOUR_PARTEF, 0, 0, 0, 0, 0])\n",
        "    Cam_T_PatRef = translate_along_x @ translate_away_from_camera\n",
        "    pat_ref_cam = multiply_points_by_transform(pat_ref_marker, Cam_T_PatRef)\n",
        "    PatRef_T_Cam = np.linalg.inv(Cam_T_PatRef)\n",
        "\n",
        "    # 4) obtaining PatRef_T_MRI\n",
        "    PatRef_T_MRI = extrinsic_vecs_to_matrix([X_T, Y_T, Z_T, 0, 0, 0])\n",
        "    MRI_T_PatRef = np.linalg.inv(PatRef_T_MRI)\n",
        "\n",
        "    return MRI_T_PatRef, PatRef_T_Cam, Cam_T_PntRef, PntRef_T_PntTip, pnt_ref_marker, pnt_ref_cam, pat_ref_marker, pat_ref_cam\n"
      ],
      "metadata": {
        "id": "4LQQlpUNFMfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MRI_T_PatRef, PatRef_T_Cam, Cam_T_PntRef, PntRef_T_PntTip, pnt_ref_marker, pnt_ref_cam, pat_ref_marker, pat_ref_cam = get_transforms(pointer_length=100)"
      ],
      "metadata": {
        "id": "SywFAHo1lZkA",
        "outputId": "8805d482-5146-44bf-c993-108d9d159ab5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pointer length: 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('our 4 transforms:')\n",
        "\n",
        "print('PatRef_T_MRI')\n",
        "print(MRI_T_PatRef)\n",
        "\n",
        "print('Cam_T_PatRef')\n",
        "print(PatRef_T_Cam)\n",
        "\n",
        "print('Cam_T_PntRef')\n",
        "print(Cam_T_PntRef)\n",
        "\n",
        "print('PntRef_T_PntTip')\n",
        "print(PntRef_T_PntTip)\n",
        "\n",
        "\n",
        "print('reference frames represented in different coordinate systems')\n",
        "print('pnt_ref_marker')\n",
        "print(pnt_ref_marker)\n",
        "\n",
        "print('pnt_ref_cam')\n",
        "print(pnt_ref_cam)\n",
        "\n",
        "print('pat_ref_marker')\n",
        "print(pat_ref_marker)\n",
        "\n",
        "print('pat_ref_cam')\n",
        "print(pat_ref_cam)"
      ],
      "metadata": {
        "id": "xxN2u8Xul0Kp",
        "outputId": "45785eae-692f-418c-c6f7-e7dde767b6e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "our 4 transforms:\n",
            "PatRef_T_MRI\n",
            "[[   1.    0.    0. -100.]\n",
            " [   0.    1.    0. -130.]\n",
            " [   0.    0.    1.  -80.]\n",
            " [   0.    0.    0.    1.]]\n",
            "Cam_T_PatRef\n",
            "[[ 1.e+00  0.e+00  0.e+00 -3.e+02]\n",
            " [ 0.e+00  1.e+00  0.e+00  0.e+00]\n",
            " [ 0.e+00  0.e+00  1.e+00 -2.e+03]\n",
            " [ 0.e+00  0.e+00  0.e+00  1.e+00]]\n",
            "Cam_T_PntRef\n",
            "[[ 7.07106781e-01 -7.07106781e-01  0.00000000e+00  0.00000000e+00]\n",
            " [ 7.07106781e-01  7.07106781e-01  0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  1.00000000e+00  2.00000000e+03]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
            "PntRef_T_PntTip\n",
            "[[   1.    0.    0.    0.]\n",
            " [   0.    1.    0. -100.]\n",
            " [   0.    0.    1.    0.]\n",
            " [   0.    0.    0.    1.]]\n",
            "reference frames represented in different coordinate systems\n",
            "pnt_ref_marker\n",
            "[[  0.   0.   0.   1.]\n",
            " [  0.  50.   0.   1.]\n",
            " [ 25. 100.   0.   1.]\n",
            " [-25. 135.   0.   1.]]\n",
            "pnt_ref_cam\n",
            "[[ 0.00000000e+00  0.00000000e+00  2.00000000e+03  1.00000000e+00]\n",
            " [-3.53553391e+01  3.53553391e+01  2.00000000e+03  1.00000000e+00]\n",
            " [-5.30330086e+01  8.83883476e+01  2.00000000e+03  1.00000000e+00]\n",
            " [-1.13137085e+02  7.77817459e+01  2.00000000e+03  1.00000000e+00]]\n",
            "pat_ref_marker\n",
            "[[  0.     0.     0.     1.  ]\n",
            " [ 41.02   0.    28.59   1.  ]\n",
            " [ 88.     0.     0.     1.  ]\n",
            " [ 40.45   0.   -44.32   1.  ]]\n",
            "pat_ref_cam\n",
            "[[3.00000e+02 0.00000e+00 2.00000e+03 1.00000e+00]\n",
            " [3.41020e+02 0.00000e+00 2.02859e+03 1.00000e+00]\n",
            " [3.88000e+02 0.00000e+00 2.00000e+03 1.00000e+00]\n",
            " [3.40450e+02 0.00000e+00 1.95568e+03 1.00000e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def add_noise_to_points(points_in, sigma):\n",
        "    \"\"\"\n",
        "    add_noise_to_points(points_in, sigma)\n",
        "    adding noise to 3D points\n",
        "\n",
        "    Args:\n",
        "        points_in: 3xN matrix of points we are adding noise to\n",
        "        sigma: standard deviation of normal distribution defining noise distribution\n",
        "\n",
        "    Returns:\n",
        "        same points but with random noise added to them\n",
        "    \"\"\"\n",
        "    \n",
        "    points_out = np.zeros((points_in.shape))\n",
        "    for r in range(points_in.shape[0]):\n",
        "        for c in range(points_in.shape[1]):\n",
        "            points_out[r][c] = points_in[r][c] + random.normalvariate(0, sigma)\n",
        "    return points_out\n",
        "\n",
        "\n",
        "def add_noise_to_params(params, sigma):\n",
        "    \"\"\"\n",
        "    add_noise_to_params(params, sigma)\n",
        "    adds noise to parameters (translation, rotation etc)\n",
        "\n",
        "    Args:\n",
        "        params: list of all parameters (translations in xyz, rotations in etc.)\n",
        "        sigma: standard deviation of normal noise to add\n",
        "\n",
        "    Returns:\n",
        "        parameters with noise added on them\n",
        "    \"\"\"\n",
        "    params_out = copy.deepcopy(params)\n",
        "    for i, p in enumerate(params):\n",
        "        params_out[i] = params[i] + random.normalvariate(0, sigma)\n",
        "    return params_out\n",
        "\n",
        "\n",
        "def calculate_euclid_dist(pointer_tip_in_mri_space,tumour_in_mri_space ):\n",
        "    \"\"\"\n",
        "    calculate_euclid_dist(pointer_tip_in_mri_space,tumour_in_mri_space )\n",
        "    calculates euclidean distance between two 3D points (euclid_dist is x^2+y^2+x^2)\n",
        "\n",
        "    Args:\n",
        "        pointer_tip_in_mri_space: 4x1 np array of where we think the tumor is\n",
        "        tumour_in_mri_space: 4x1 np array of where the tumor actually is\n",
        "\n",
        "    Returns:\n",
        "        euclidean distance between the two points\n",
        "    \"\"\"\n",
        "\n",
        "    dist =  (pointer_tip_in_mri_space[0] - tumour_in_mri_space[0]) \\\n",
        "            * (pointer_tip_in_mri_space[0] - tumour_in_mri_space[0]) \\\n",
        "            + (pointer_tip_in_mri_space[1] - tumour_in_mri_space[1]) \\\n",
        "            * (pointer_tip_in_mri_space[1] - tumour_in_mri_space[1]) \\\n",
        "            + (pointer_tip_in_mri_space[2] - tumour_in_mri_space[2]) \\\n",
        "            * (pointer_tip_in_mri_space[2] - tumour_in_mri_space[2])\n",
        "\n",
        "    return dist\n",
        "\n"
      ],
      "metadata": {
        "id": "I_O48pDgzpf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sksurgerycore.algorithms.procrustes as pro\n",
        "\n",
        "A = np.array([\n",
        "    [0,0,0],\n",
        "    [0,10,0],\n",
        "    [0,20,0]\n",
        "])\n",
        "\n",
        "B = np.array([\n",
        "    [10,0,-10],\n",
        "    [10,10,-10],\n",
        "    [10,20,-10]\n",
        "])\n",
        "\n",
        "\n",
        "R, t, FRE = pro.orthogonal_procrustes(B,A)\n",
        "\n",
        "B_T_A = mu.construct_rigid_transformation(R, t)\n",
        "\n",
        "print(B_T_A @ np.array([0,0,0,1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKGcutM7K5La",
        "outputId": "d281be58-6736-4e4b-d31b-86b3e1c90560"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 10.   0. -10.   1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def simulation(PatRef_T_Cam=0, Cam_T_PntRef=0, PntRef_T_PntTip=0, MRI_T_PatRef=0, pnt_ref_marker=0, pnt_ref_cam=0,\n",
        "               pat_ref_marker=0, pat_ref_cam=0, add_reg_error=False, add_tracking_noise=False, varying_length=False):\n",
        "    \"\"\"\n",
        "    This function simulates the tracking of a pointer using a camera-based system, and evaluates the accuracy of the\n",
        "    tracked pointer in MRI space. The function can simulate different scenarios by adding noise to the reference points\n",
        "    in camera space or adding error to the registration between patient space and MRI space. The function returns the\n",
        "    root mean squared (RMS) error between the target location of the pointer in MRI space and the tracked location.\n",
        "\n",
        "    Args:\n",
        "        The following are rigid transformations from the coordinate system on the right of T\n",
        "            to the coordinate system on the left of T\n",
        "        PatRef_T_Cam (numpy.ndarray): The rigid transformation from the camera frame to the patient reference frame .\n",
        "        Cam_T_PntRef (numpy.ndarray): from the pointer reference frame to the camera frame.\n",
        "        PntRef_T_PntTip (numpy.ndarray): from the pointer tip reference frame to the pointer\n",
        "            reference frame.\n",
        "        MRI_T_PatRef (numpy.ndarray): from the patient reference frame to the MRI reference frame \n",
        "\n",
        "        pnt_ref_marker (numpy.ndarray): The position of the pointer reference frame in marker space.\n",
        "        pnt_ref_cam (numpy.ndarray): The position of the pointer reference frame in camera space.\n",
        "        pat_ref_marker (numpy.ndarray): The position of the patient reference frame in marker space.\n",
        "        pat_ref_cam (numpy.ndarray): The position of the patient reference frame in camera space.\n",
        "\n",
        "        add_reg_error (bool): If True, add noise to the parameters of the registration between the patient reference\n",
        "            frame and the MRI reference frame.\n",
        "        add_tracking_noise (bool): If True, add noise to the position of the reference frames in camera space.\n",
        "        varying_length (bool): If True, return the RMS error only for certain values of sigma.\n",
        "        This is so we can plot varying lengths.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: The x-values of the RMS error plot.\n",
        "        numpy.ndarray: The y-values of the RMS error plot.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    x_values = []\n",
        "    y_values = []\n",
        "\n",
        "    # create a target location at the tip of the pointer in marker space\n",
        "    target_location_in_marker_space = np.zeros((4, 1))\n",
        "    target_location_in_marker_space[3, 0] = 1  # homogeous\n",
        "\n",
        "    # compute the transform from MRI to point at tip of pointer\n",
        "    MRI_T_PntTip = MRI_T_PatRef @ PatRef_T_Cam @ Cam_T_PntRef @ PntRef_T_PntTip\n",
        "    # transform target location to MRI space\n",
        "    target_location_in_mri_space = MRI_T_PntTip @ target_location_in_marker_space\n",
        "    \n",
        "    ###### CHANGE ALL PatRef_T_Cam AND MRI_T_PatRef\n",
        "    MRI_T_PatRef_original = copy.deepcopy(MRI_T_PatRef)\n",
        "\n",
        "    for sigma in np.arange(0, END_SIGMA + SIGMA_STEP, SIGMA_STEP):\n",
        "        # sigma = float(sigma_counter) / float(100)\n",
        "        # print(sigma)\n",
        "        rms = 0\n",
        "        for i in range(NUMBER_SAMPLES):\n",
        "\n",
        "            if add_tracking_noise:\n",
        "                # add tracking noise to the reference points in camera space\n",
        "                noisy_pnt_ref_cam = add_noise_to_points(pnt_ref_cam[:, 0:3], sigma)\n",
        "                # compute transforms with the noisy reference points (from references to camera)\n",
        "                R, t, FRE = pro.orthogonal_procrustes(noisy_pnt_ref_cam[:, 0:3], pnt_ref_marker[:, 0:3])\n",
        "                Cam_T_PntRef = mu.construct_rigid_transformation(R, t)\n",
        "\n",
        "                # same for patient reference\n",
        "                noisy_pat_ref_cam = add_noise_to_points(pat_ref_cam[:, 0:3], sigma)\n",
        "                R, t, FRE = pro.orthogonal_procrustes(pat_ref_marker[:, 0:3], noisy_pat_ref_cam[:, 0:3])\n",
        "                PatRe_T_Cam = mu.construct_rigid_transformation(R, t)\n",
        "\n",
        "            if add_reg_error:\n",
        "                # Here we add noise onto the PatRef_T_MRI_parameters, and reconstruct a new registration\n",
        "                MRI_T_PatRef_parameters = extrinsic_matrix_to_vecs(MRI_T_PatRef_original)\n",
        "                MRI_T_PatRef_noisy_parameters = add_noise_to_params(MRI_T_PatRef_parameters, sigma)\n",
        "                MRI_T_PatRef = extrinsic_vecs_to_matrix(MRI_T_PatRef_noisy_parameters)\n",
        "\n",
        "            # use noisy transforms to get a target location from camera space to MRI space.            \n",
        "            MRI_T_PntTip_noisy = MRI_T_PatRef @ PatRef_T_Cam @ Cam_T_PntRef @ PntRef_T_PntTip\n",
        "            transformed_point_noisy = MRI_T_PntTip_noisy @ target_location_in_marker_space\n",
        "\n",
        "            # calculate euclidean distance between noisy transformed point and target location in MRI space\n",
        "            euclid_dist = calculate_euclid_dist(transformed_point_noisy, target_location_in_mri_space)\n",
        "            rms = rms + float(euclid_dist)\n",
        "\n",
        "        # calculating root mean square\n",
        "        rms = rms / float(NUMBER_SAMPLES)\n",
        "        rms = np.sqrt(rms)\n",
        "\n",
        "        if varying_length:\n",
        "            if sigma == 0.12 or sigma == 0.15 or sigma == 0.25 or sigma == 0.2 or sigma == 0.5:\n",
        "                x_values.append(sigma)\n",
        "                y_values.append(rms)\n",
        "        else:\n",
        "            x_values.append(sigma)\n",
        "            y_values.append(rms)\n",
        "\n",
        "    return np.array(x_values), np.array(y_values)\n",
        "\n"
      ],
      "metadata": {
        "id": "E99sq789Z0ki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tracking_error_12, tracking_error_15, tracking_error_25, tracking_error_20\n",
        "tracking_x_values, tracking_y_values \\\n",
        "    = simulation(PatRef_T_Cam=PatRef_T_Cam, \\\n",
        "                  Cam_T_PntRef=Cam_T_PntRef, PntRef_T_PntTip=PntRef_T_PntTip, MRI_T_PatRef=MRI_T_PatRef, \\\n",
        "                  pnt_ref_marker=pnt_ref_marker, pnt_ref_cam=pnt_ref_cam, \\\n",
        "                  pat_ref_marker=pat_ref_marker, pat_ref_cam=pat_ref_cam, add_reg_error=False,\n",
        "                  add_tracking_noise=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "MhkMIRE_zUqj",
        "outputId": "532b8669-8b64-4116-f318-63e86f68c427"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-109-1f76a26e1a7b>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# tracking_error_12, tracking_error_15, tracking_error_25, tracking_error_20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtracking_x_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracking_y_values\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     = simulation(PatRef_T_Cam=PatRef_T_Cam, \\\n\u001b[0m\u001b[1;32m      4\u001b[0m                   \u001b[0mCam_T_PntRef\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCam_T_PntRef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPntRef_T_PntTip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPntRef_T_PntTip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMRI_T_PatRef\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMRI_T_PatRef\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                   \u001b[0mpnt_ref_marker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpnt_ref_marker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpnt_ref_cam\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpnt_ref_cam\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-108-dc8684f1aa17>\u001b[0m in \u001b[0;36msimulation\u001b[0;34m(PatRef_T_Cam, Cam_T_PntRef, PntRef_T_PntTip, MRI_T_PatRef, pnt_ref_marker, pnt_ref_cam, pat_ref_marker, pat_ref_cam, add_reg_error, add_tracking_noise, varying_length)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0madd_tracking_noise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0;31m# add tracking noise to the reference points in camera space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mnoisy_pnt_ref_cam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_noise_to_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpnt_ref_cam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m                 \u001b[0;31m# compute transforms with the noisy reference points (from references to camera)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFRE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morthogonal_procrustes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy_pnt_ref_cam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpnt_ref_marker\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-61-1b0cd644dc09>\u001b[0m in \u001b[0;36madd_noise_to_points\u001b[0;34m(points_in, sigma)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints_in\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints_in\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mpoints_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoints_in\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalvariate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpoints_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}
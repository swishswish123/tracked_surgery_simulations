{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMAaT4akeVRzdd1EjpKvXJs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swishswish123/tracked_surgery_simulations/blob/main/tracked_endoscope.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) TRACKED ENDOSCOPE SIMULATION\n",
        "\n",
        "In this notebook we want to study the accuracy of a tracked endoscope, and what the expected accuracy of an overlay will be. The overlay accuracy could be measured in terms of accuracy in 3D in the endoscope camera frame, or in terms of 2D pixel accuracy.\n",
        "\n",
        "Please first read tracked_pointer.ipynb before this notebook for a better understanding of the problem and the maths behind it."
      ],
      "metadata": {
        "id": "IekbERjTlXuf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## imports and utility functions\n"
      ],
      "metadata": {
        "id": "VE7ThQKImkF9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSmWxIolkcdw"
      },
      "outputs": [],
      "source": [
        "# github repo which contains all the images\n",
        "!git clone https://github.com/swishswish123/tracked_surgery_simulations.git repo\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial.transform import Rotation as spr\n"
      ],
      "metadata": {
        "id": "mKyNLNCmm43X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extrinsic_matrix_to_vecs(matrix):\n",
        "    \"\"\"\n",
        "    extract_rigid_body_parameters(matrix)\n",
        "    extracts parameters from transformation matrix\n",
        "\n",
        "    Args:\n",
        "        matrix: 4x4 transformation matrix\n",
        "\n",
        "    Returns:\n",
        "        list of rigid body parameters [tx, ty, tz, rx, ry, rz]\n",
        "\n",
        "    \"\"\"\n",
        "    t = matrix[0:3, 3]\n",
        "    r = matrix[0:3, 0:3]\n",
        "    rot = spr.from_matrix(r)\n",
        "    euler = rot.as_euler('xyz', degrees=True)\n",
        "    return [t[0], t[1], t[2], euler[0], euler[1], euler[2]]\n",
        "\n",
        "def extrinsic_vecs_to_matrix(params):\n",
        "    \"\"\"\n",
        "    rigid_body_parameters_to_matrix(params)\n",
        "    converts a list of rigid body parameters to transformation matrix\n",
        "\n",
        "    Args:\n",
        "        params: list of rigid body parameters [tx, ty, tz, rx, ry, rz]\n",
        "\n",
        "    Returns:\n",
        "        4x4 transformation matrix of these parameters\n",
        "\n",
        "    \"\"\"\n",
        "    matrix = np.eye(4)\n",
        "    \n",
        "    matrix[0][3] = params[0]\n",
        "    matrix[1][3] = params[1]\n",
        "    matrix[2][3] = params[2]\n",
        "\n",
        "    r = (spr.from_euler('xyz', [params[3], params[4], params[5]], degrees=True)).as_matrix()\n",
        "    matrix[0:3, 0:3] = r\n",
        "    return matrix\n"
      ],
      "metadata": {
        "id": "x_1kpUJUm5LJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Background, System Layout, goal and assumptions\n",
        "\n",
        "The following diagram shows the layout of the navigation system and the different components involved in the surgery when using a tracked endoscope for AR.\n",
        "\n"
      ],
      "metadata": {
        "id": "U3eTEzkMm5jm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image(filename=\"./repo/assets/endoscope_setup.png\")\n"
      ],
      "metadata": {
        "id": "kt6MP2Rsm9kl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal is to be able to display some segmented piece of information from the pre-operative MRI in MRI coordinates onto the endoscopic video:"
      ],
      "metadata": {
        "id": "NpQ50pCrn10d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image(filename=\"./repo/assets/endoscope_goal.png\")\n"
      ],
      "metadata": {
        "id": "OZZkGkz58gte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal is therefore turning some segmented MRI coordinates to Endoscopic Image (EndIm) coordinates.\n",
        "\n",
        "X<sub>EndIm</sub> = T X<sub>MRI</sub>\n",
        "\n",
        "where T is composed of the following transforms:\n",
        "\n",
        "T = <sup>EndIm</sup>T<sub>EndP</sub> * \n",
        "    <sup>EndP</sup>T<sub>EndRef</sub> * \n",
        "    <sup>EndRef</sup>T<sub>Cam</sub>  * \n",
        "    <sup>Cam</sup>T<sub>PatRef</sub> * \n",
        "    <sup>PatRef</sup>T<sub>MRI</sub>\n",
        "    \n",
        "\n",
        "\n",
        "Here is an visual representation of the endoscope setup with all the transforms:\n"
      ],
      "metadata": {
        "id": "5wAOI6_E8ivl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image(filename=\"endosim_demo/images/endoscope_setup_transforms.png\")"
      ],
      "metadata": {
        "id": "cyJav1wi9Nyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following sections we will go step by step on how to go from each of these transforms"
      ],
      "metadata": {
        "id": "xFSA6w4Q9M3b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assumptions"
      ],
      "metadata": {
        "id": "j2cCDL5WoNNQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to make this a like-for-like comparison to the tracked pointer simulation, we should keep most of the reference data identical. The difference now, is we swap a pointer for an endoscope. We will need an additional hand-eye calibration, and reference data to project from camera space onto image space, but we leave all other data the same. "
      ],
      "metadata": {
        "id": "Hh60MSyY5PGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image(filename=\"endosim_demo/images/endoscope_setup_assumptions.png\")\n"
      ],
      "metadata": {
        "id": "spWW50qr958I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# P - , the length of the endoscope.\n",
        "LENGTH_OF_ENDOSCOPE = 180 # use 300 after merging\n",
        "\n",
        "# D - z distance from camera to plane where everything is located\n",
        "DISTANCE_FROM_CAM = 2000 # since the camera and patient reference are aligned in the x and y directions, only distance is in z\n",
        "\n",
        "# 0 - angle of pointer\n",
        "ENDOSCOPE_ANGLE = 45\n",
        "\n",
        "# Yc - distances from tumour to patient reference\n",
        "TUMOUR_PATREF = 300  \n",
        "\n",
        "# NDI quotes 0.25mm for Polaris Spectra, some papers estimate it at 0.17mm\n",
        "#TYPICAL_TRACKING_SIGMA = 0.25\n",
        "\n",
        "# For Model 2 and 3, using an endoscope, this determines the distance of a target of interest from the endoscope.\n",
        "#working_distance = 50\n",
        "\n",
        "# for simulation to be reproducible\n",
        "NUMBER_SAMPLES = 10\n",
        "\n",
        "X_T = 100 # head length (about 20cm)\n",
        "Y_T = 130 # menton to top of head (about 25cm)\n",
        "Z_T = 80 # head bredth (about 15cm)\n",
        "\n",
        "END_SIGMA=0.5\n",
        "SIGMA_STEP=0.01"
      ],
      "metadata": {
        "id": "IoJlEzgLoH3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining references\n",
        "\n",
        "We will use the same reference coordinates as used by the pointer in this simulation to ensure the two are easily comparable.\n",
        "\n",
        "The patient reference will be set up exactly the same. However, what was previously the pointer reference will now be the endoscope reference (EndRef) and so instead of the pointer length there will be an endoscope length between the endoscope's camera, and the first marker."
      ],
      "metadata": {
        "id": "csoG9L2BIk0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_pat_ref():\n",
        "    \"\"\"\n",
        "    Create reference coordinates of a marker pattern in a numpy matrix.\n",
        "\n",
        "    This function creates a numpy matrix containing the reference coordinates of a marker pattern used for\n",
        "    pose estimation. The marker pattern consists of four markers labeled A, B, C and D. The reference coordinates\n",
        "    of each marker point are defined in a right-handed reference frame as follows:\n",
        "\n",
        "        Marker A: (0, 0, 0)\n",
        "        Marker B: (41.02, 0, 28.59)\n",
        "        Marker C: (88.00, 0, 0)\n",
        "        Marker D: (40.45, 0, -44.32)\n",
        "\n",
        "    The function returns a 4x4 numpy matrix containing the homogenous coordinates of each marker point, with the\n",
        "    last element of each row set to 1.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: A 4x4 numpy matrix containing reference coordinates of a marker pattern. Each row represents a\n",
        "        marker point in homogenous coordinates.\n",
        "    \"\"\"\n",
        "\n",
        "    # Encoding the reference marker points into a numpy matrix\n",
        "    pat_ref = np.zeros((4, 4))\n",
        "    # marker A (0) -> (0,0,0)\n",
        "\n",
        "    # marker B (1) -> (41.02 ,0,28.59)\n",
        "    pat_ref[1][0] = 41.02  # x\n",
        "    pat_ref[1][2] = 28.59  # z\n",
        "\n",
        "    # marker C (2) -> C = (88.00 ,0, 0)\n",
        "    pat_ref[2][0] = 88  # x\n",
        "\n",
        "    # marker D (3) -> (40.45,0,-44.32)\n",
        "    pat_ref[3][0] = 40.45  # x\n",
        "    pat_ref[3][2] = -44.32  # z\n",
        "\n",
        "    # adding 1 to last row to make coordinates homogenous\n",
        "    pat_ref[0][3] = 1.0\n",
        "    pat_ref[1][3] = 1.0\n",
        "    pat_ref[2][3] = 1.0\n",
        "    pat_ref[3][3] = 1.0\n",
        "    return pat_ref\n",
        "\n",
        "\n",
        "def create_end_ref():\n",
        "    \"\"\"\n",
        "    Creates a numpy matrix representing the endoscope reference coordinates.\n",
        "\n",
        "    Returns:\n",
        "    end_ref (numpy matrix): A 4x4 numpy matrix containing the pointer reference coordinates\n",
        "                            as row vectors in homogenous coordinates. The four rows represent\n",
        "                            the markers A, B, C, and D in that order.\n",
        "    \"\"\"\n",
        "    # Creating pointer reference (from datasheet). Using homogenous (4 numbers, x,y,z,1) as row vectors.\n",
        "    end_ref = np.zeros((4, 4))\n",
        "\n",
        "    # marker A (0) -> 0,0,0\n",
        "\n",
        "    # marker B (1) -> 0,50,0\n",
        "    end_ref[1][1] = 50  # y\n",
        "\n",
        "    # marker c (2) -> 25,100,0\n",
        "    end_ref[2][0] = 25  # x\n",
        "    end_ref[2][1] = 100  # y\n",
        "\n",
        "    # marker d (3) -> -25, 135, 0\n",
        "    end_ref[3][0] = -25  # x\n",
        "    end_ref[3][1] = 135  # y\n",
        "\n",
        "    # adding 1 to 3rd dimension to turn to homogeneous coordinates\n",
        "    end_ref[0][3] = 1\n",
        "    end_ref[1][3] = 1\n",
        "    end_ref[2][3] = 1\n",
        "    end_ref[3][3] = 1\n",
        "\n",
        "    return end_ref"
      ],
      "metadata": {
        "id": "f4vAWXLGIkO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Obtaining transforms\n",
        "\n",
        "\n",
        "Remember we want at the end a composition of all these transforms:\n",
        "\n",
        "T = <sup>EndIm</sup>T<sub>EndP</sub> * \n",
        "    <sup>EndP</sup>T<sub>EndRef</sub> * \n",
        "    <sup>EndRef</sup>T<sub>Cam</sub>  * \n",
        "    <sup>Cam</sup>T<sub>PatRef</sub> * \n",
        "    <sup>PatRef</sup>T<sub>MRI</sub>\n",
        "  \n",
        "Most of these are obtained in a similar way to the pointer simulation although flipped as we are going from the MRI coordinates. Since we are assuming the layout and relative positions of each reference marker, we are able to obtain the transformations between each coordinate system.\n",
        "\n",
        "The function below generates these transformations with the given pointer length and the parameters defined in the assumptions section."
      ],
      "metadata": {
        "id": "VmXpSbLrKUcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_transforms(endoscope_length=200, ENDOSCOPE_ANGLE=45,DISTANCE_FROM_CAM=2000, TUMOUR_PARTEF=40  ):\n",
        "    \"\"\"\n",
        "    Returns a set of coordinate transformation matrices that convert points from one reference frame to another.\n",
        "\n",
        "    Args:\n",
        "        endoscope_length (float): Length of the endoscope in millimeters. Default is 200.\n",
        "        ENDOSCOPE_ANGLE (float): z angle at which endoscope is angled\n",
        "        DISTANCE_FROM_CAM (float): distance from camera to patient\n",
        "        TUMOUR_PARTEF (float): distance from tumour to patient reference\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the following eight transformation matrices:\n",
        "        - PatRef_T_MRI: A 4x4 transformation matrix that converts points from the MRI reference frame to the patient reference frame.\n",
        "        - Cam_T_PatRef: A 4x4 transformation matrix that converts points from the patient reference frame to the camera reference frame.\n",
        "        - EndRef_T_Cam: A 4x4 transformation matrix that converts points from the camera reference frame to the endoscope reference frame. \n",
        "        - EndP_T_EndRef: A 4x4 transformation matrix that converts points from the endoscope reference frame to the endoscope tip reference frame.\n",
        "\n",
        "        and the following numpy arrays containing the homogenous coordinates of the points in the given reference frame\n",
        "        - end_ref_marker:  endRef in the pointer reference frame.\n",
        "        - end_ref_cam: endRef in the camera reference frame.\n",
        "        \n",
        "        - pat_ref_marker: patRef in the patient reference frame.\n",
        "        - pat_ref_cam: patRef in the camera reference frame.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # 1) obtaining EndRef_T_EndP\n",
        "    #print(f'endoscope length: {endoscope_length}')\n",
        "    # Creating pointer reference in the pointer reference frame.\n",
        "    end_ref_marker = create_end_ref() # marker coords\n",
        "    # Point reference to point tip: (pointer length translation in y)\n",
        "    EndP_T_EndRef = extrinsic_vecs_to_matrix(\n",
        "        [0, pointer_length, 0, 0, 0, 0]) # create transform of all points depending on pointer's length\n",
        "    # invert to get tip to ref:\n",
        "    #EndRef_T_EndP = np.linalg.inv(EndP_T_EndRef)\n",
        "\n",
        "    # 2) obtaining Cam_T_EndRef\n",
        "    # Converting the marker points to the camera reference frame by applying a\n",
        "    # rotation of ENDOSCOPE_ANGLE degrees about the z-axis followed by a\n",
        "    # translation of DISTANCE_FROM_CAM along the z-axis of camera.\n",
        "    rotate_about_z = extrinsic_vecs_to_matrix([0, 0, 0, 0, 0, ENDOSCOPE_ANGLE])\n",
        "    translate_away_from_camera = extrinsic_vecs_to_matrix([0, 0, DISTANCE_FROM_CAM, 0, 0, 0])\n",
        "    Cam_T_EndRef = translate_away_from_camera @ rotate_about_z\n",
        "    end_ref_cam = multiply_points_by_transform(end_ref_marker, Cam_T_EndRef)\n",
        "    EndRef_T_Cam = np.linalg.inv(Cam_T_EndRef)\n",
        "\n",
        "    # 3) obtaining Cam_T_PatRef\n",
        "    # PatRef to Cam (add dist to cam to z plus x translation to right)\n",
        "    pat_ref_marker = create_pat_ref()\n",
        "    # translating to correct location \n",
        "    translate_along_x = extrinsic_vecs_to_matrix([TUMOUR_PARTEF, 0, 0, 0, 0, 0])\n",
        "    Cam_T_PatRef = translate_along_x @ translate_away_from_camera\n",
        "    pat_ref_cam = multiply_points_by_transform(pat_ref_marker, Cam_T_PatRef)\n",
        "    #PatRef_T_Cam = np.linalg.inv(Cam_T_PatRef)\n",
        "\n",
        "    # 4) obtaining PatRef_T_MRI\n",
        "    PatRef_T_MRI = extrinsic_vecs_to_matrix([X_T, Y_T, Z_T, 0, 0, 0])\n",
        "    #MRI_T_PatRef = np.linalg.inv(PatRef_T_MRI)\n",
        "\n",
        "    return EndP_T_EndRef,EndRef_T_Cam,Cam_T_PatRef,PatRef_T_MRI  , end_ref_marker, end_ref_cam, pat_ref_marker, pat_ref_cam\n"
      ],
      "metadata": {
        "id": "rSDaIQm1KRsE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPr9tdSk1Ca2NHYGbX0AYM7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swishswish123/tracked_surgery_simulations/blob/main/tracked_endoscope.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) TRACKED ENDOSCOPE SIMULATION\n",
        "\n",
        "In this notebook we want to study the accuracy of a tracked endoscope, and what the expected accuracy of an overlay will be. The overlay accuracy could be measured in terms of accuracy in 3D in the endoscope camera frame, or in terms of 2D pixel accuracy.\n",
        "\n",
        "Please first read tracked_pointer.ipynb before this notebook for a better understanding of the problem and the maths behind it."
      ],
      "metadata": {
        "id": "IekbERjTlXuf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## imports and utility functions\n"
      ],
      "metadata": {
        "id": "VE7ThQKImkF9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSmWxIolkcdw"
      },
      "outputs": [],
      "source": [
        "# github repo which contains all the images\n",
        "!git clone https://github.com/swishswish123/tracked_surgery_simulations.git repo\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install necessary packages\n",
        "!pip install scikit-surgerycore"
      ],
      "metadata": {
        "id": "xa7VVIbwcETF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import necessary packages\n",
        "from scipy.spatial.transform import Rotation as spr\n",
        "from IPython.display import Image\n",
        "import cv2\n",
        "import copy\n",
        "import sksurgerycore.transforms.matrix as mu\n",
        "from scipy.spatial.transform import Rotation as spr\n",
        "import sksurgerycore.algorithms.procrustes as pro\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n"
      ],
      "metadata": {
        "id": "mKyNLNCmm43X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extrinsic_matrix_to_vecs(matrix):\n",
        "    \"\"\"\n",
        "    extract_rigid_body_parameters(matrix)\n",
        "    extracts parameters from transformation matrix\n",
        "\n",
        "    Args:\n",
        "        matrix: 4x4 transformation matrix\n",
        "\n",
        "    Returns:\n",
        "        list of rigid body parameters [tx, ty, tz, rx, ry, rz]\n",
        "\n",
        "    \"\"\"\n",
        "    t = matrix[0:3, 3]\n",
        "    r = matrix[0:3, 0:3]\n",
        "    rot = spr.from_matrix(r)\n",
        "    euler = rot.as_euler('xyz', degrees=True)\n",
        "    return [t[0], t[1], t[2], euler[0], euler[1], euler[2]]\n",
        "\n",
        "def extrinsic_vecs_to_matrix(params):\n",
        "    \"\"\"\n",
        "    rigid_body_parameters_to_matrix(params)\n",
        "    converts a list of rigid body parameters to transformation matrix\n",
        "\n",
        "    Args:\n",
        "        params: list of rigid body parameters [tx, ty, tz, rx, ry, rz]\n",
        "\n",
        "    Returns:\n",
        "        4x4 transformation matrix of these parameters\n",
        "\n",
        "    \"\"\"\n",
        "    matrix = np.eye(4)\n",
        "    \n",
        "    matrix[0][3] = params[0]\n",
        "    matrix[1][3] = params[1]\n",
        "    matrix[2][3] = params[2]\n",
        "\n",
        "    r = (spr.from_euler('xyz', [params[3], params[4], params[5]], degrees=True)).as_matrix()\n",
        "    matrix[0:3, 0:3] = r\n",
        "    return matrix\n",
        "\n",
        "\n",
        "def multiply_points_by_transform(D3_hom, T):\n",
        "    \"\"\"\n",
        "    Applies a 4x4 transformation matrix to a set of 3D points.\n",
        "\n",
        "    Args:\n",
        "        D3_points (numpy.ndarray): Array of 3D points with shape (N, 3).\n",
        "        T (numpy.ndarray): 4x4 transformation matrix.\n",
        "\n",
        "    Returns:\n",
        "        (numpy.ndarray) Array of transformed 3D points with shape (N, 3).\n",
        "    \"\"\"\n",
        "    D3_transformed_points_hom = T @ D3_hom.T\n",
        "    return D3_transformed_points_hom.T"
      ],
      "metadata": {
        "id": "x_1kpUJUm5LJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Background, System Layout, goal and assumptions\n",
        "\n",
        "The following diagram shows the layout of the navigation system and the different components involved in the surgery when using a tracked endoscope for AR.\n",
        "\n"
      ],
      "metadata": {
        "id": "U3eTEzkMm5jm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image(filename=\"./repo/assets/endoscope_setup.png\")\n"
      ],
      "metadata": {
        "id": "kt6MP2Rsm9kl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal is to be able to display some segmented piece of information from the pre-operative MRI in MRI coordinates onto the endoscopic video:"
      ],
      "metadata": {
        "id": "NpQ50pCrn10d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image(filename=\"./repo/assets/endoscope_goal.png\")\n"
      ],
      "metadata": {
        "id": "OZZkGkz58gte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal is therefore turning some segmented MRI coordinates to Endoscopic Image (EndIm) coordinates.\n",
        "\n",
        "X<sub>EndIm</sub> = T X<sub>MRI</sub>\n",
        "\n",
        "where T is composed of the following transforms:\n",
        "\n",
        "T = <sup>EndIm</sup>T<sub>EndP</sub> * \n",
        "    <sup>EndP</sup>T<sub>EndRef</sub> * \n",
        "    <sup>EndRef</sup>T<sub>Cam</sub>  * \n",
        "    <sup>Cam</sup>T<sub>PatRef</sub> * \n",
        "    <sup>PatRef</sup>T<sub>MRI</sub>\n",
        "    \n",
        "\n",
        "\n",
        "Here is an visual representation of the endoscope setup with all the transforms:\n"
      ],
      "metadata": {
        "id": "5wAOI6_E8ivl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image(filename=\"./repo/assets/endoscope_setup_transforms.png\")"
      ],
      "metadata": {
        "id": "cyJav1wi9Nyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following sections we will go step by step on how to go from each of these transforms"
      ],
      "metadata": {
        "id": "xFSA6w4Q9M3b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assumptions"
      ],
      "metadata": {
        "id": "j2cCDL5WoNNQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to make this a like-for-like comparison to the tracked pointer simulation, we should keep most of the reference data identical. The difference now, is we swap a pointer for an endoscope. We will need an additional hand-eye calibration, and reference data to project from camera space onto image space, but we leave all other data the same. "
      ],
      "metadata": {
        "id": "Hh60MSyY5PGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image(filename=\"./repo/assets/endoscope_setup_assumptions.png\")\n"
      ],
      "metadata": {
        "id": "spWW50qr958I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# P - , the length of the endoscope.\n",
        "ENDOSCOPE_LENGTH = 180 # use 300 after merging\n",
        "\n",
        "# D - z distance from camera to plane where everything is located\n",
        "DISTANCE_FROM_CAM = 2000 # since the camera and patient reference are aligned in the x and y directions, only distance is in z\n",
        "\n",
        "# 0 - angle of pointer\n",
        "ENDOSCOPE_ANGLE = 45\n",
        "\n",
        "# Yc - distances from tumour to patient reference\n",
        "TUMOUR_PATREF = 300  \n",
        "\n",
        "# NDI quotes 0.25mm for Polaris Spectra, some papers estimate it at 0.17mm\n",
        "#TYPICAL_TRACKING_SIGMA = 0.25\n",
        "\n",
        "# For Model 2 and 3, using an endoscope, this determines the distance of a target of interest from the endoscope.\n",
        "#working_distance = 50\n",
        "\n",
        "# for simulation to be reproducible\n",
        "NUMBER_SAMPLES = 10000\n",
        "\n",
        "X_T = 100 # head length (about 20cm)\n",
        "Y_T = 130 # menton to top of head (about 25cm)\n",
        "Z_T = 80 # head bredth (about 15cm)\n",
        "\n",
        "END_SIGMA=0.5\n",
        "SIGMA_STEP=0.01"
      ],
      "metadata": {
        "id": "IoJlEzgLoH3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining references\n",
        "\n",
        "We will use the same reference coordinates as used by the pointer in this simulation to ensure the two are easily comparable.\n",
        "\n",
        "The patient reference will be set up exactly the same. However, what was previously the pointer reference will now be the endoscope reference (EndRef) and so instead of the pointer length there will be an endoscope length between the endoscope's camera, and the first marker."
      ],
      "metadata": {
        "id": "csoG9L2BIk0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_pat_ref():\n",
        "    \"\"\"\n",
        "    Create reference coordinates of a marker pattern in a numpy matrix.\n",
        "\n",
        "    This function creates a numpy matrix containing the reference coordinates of a marker pattern used for\n",
        "    pose estimation. The marker pattern consists of four markers labeled A, B, C and D. The reference coordinates\n",
        "    of each marker point are defined in a right-handed reference frame as follows:\n",
        "\n",
        "        Marker A: (0, 0, 0)\n",
        "        Marker B: (41.02, 0, 28.59)\n",
        "        Marker C: (88.00, 0, 0)\n",
        "        Marker D: (40.45, 0, -44.32)\n",
        "\n",
        "    The function returns a 4x4 numpy matrix containing the homogenous coordinates of each marker point, with the\n",
        "    last element of each row set to 1.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: A 4x4 numpy matrix containing reference coordinates of a marker pattern. Each row represents a\n",
        "        marker point in homogenous coordinates.\n",
        "    \"\"\"\n",
        "\n",
        "    # Encoding the reference marker points into a numpy matrix\n",
        "    pat_ref = np.zeros((4, 4))\n",
        "    # marker A (0) -> (0,0,0)\n",
        "\n",
        "    # marker B (1) -> (41.02 ,0,28.59)\n",
        "    pat_ref[1][0] = 41.02  # x\n",
        "    pat_ref[1][2] = 28.59  # z\n",
        "\n",
        "    # marker C (2) -> C = (88.00 ,0, 0)\n",
        "    pat_ref[2][0] = 88  # x\n",
        "\n",
        "    # marker D (3) -> (40.45,0,-44.32)\n",
        "    pat_ref[3][0] = 40.45  # x\n",
        "    pat_ref[3][2] = -44.32  # z\n",
        "\n",
        "    # adding 1 to last row to make coordinates homogenous\n",
        "    pat_ref[0][3] = 1.0\n",
        "    pat_ref[1][3] = 1.0\n",
        "    pat_ref[2][3] = 1.0\n",
        "    pat_ref[3][3] = 1.0\n",
        "    return pat_ref\n",
        "\n",
        "\n",
        "def create_end_ref():\n",
        "    \"\"\"\n",
        "    Creates a numpy matrix representing the endoscope reference coordinates.\n",
        "\n",
        "    Returns:\n",
        "    end_ref (numpy matrix): A 4x4 numpy matrix containing the pointer reference coordinates\n",
        "                            as row vectors in homogenous coordinates. The four rows represent\n",
        "                            the markers A, B, C, and D in that order.\n",
        "    \"\"\"\n",
        "    # Creating pointer reference (from datasheet). Using homogenous (4 numbers, x,y,z,1) as row vectors.\n",
        "    end_ref = np.zeros((4, 4))\n",
        "\n",
        "    # marker A (0) -> 0,0,0\n",
        "\n",
        "    # marker B (1) -> 0,50,0\n",
        "    end_ref[1][1] = 50  # y\n",
        "\n",
        "    # marker c (2) -> 25,100,0\n",
        "    end_ref[2][0] = 25  # x\n",
        "    end_ref[2][1] = 100  # y\n",
        "\n",
        "    # marker d (3) -> -25, 135, 0\n",
        "    end_ref[3][0] = -25  # x\n",
        "    end_ref[3][1] = 135  # y\n",
        "\n",
        "    # adding 1 to 3rd dimension to turn to homogeneous coordinates\n",
        "    end_ref[0][3] = 1\n",
        "    end_ref[1][3] = 1\n",
        "    end_ref[2][3] = 1\n",
        "    end_ref[3][3] = 1\n",
        "\n",
        "    return end_ref"
      ],
      "metadata": {
        "id": "f4vAWXLGIkO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Obtaining transforms\n",
        "\n",
        "\n",
        "Remember we want at the end a composition of all these transforms:\n",
        "\n",
        "T = <sup>EndIm</sup>T<sub>EndP</sub> * \n",
        "    <sup>EndP</sup>T<sub>EndRef</sub> * \n",
        "    <sup>EndRef</sup>T<sub>Cam</sub>  * \n",
        "    <sup>Cam</sup>T<sub>PatRef</sub> * \n",
        "    <sup>PatRef</sup>T<sub>MRI</sub>\n",
        "  \n",
        "Most of these are obtained in a similar way to the pointer simulation although flipped as we are going from the MRI coordinates. Since we are assuming the layout and relative positions of each reference marker, we are able to obtain the transformations between each coordinate system.\n",
        "\n",
        "The function below generates these transformations with the given pointer length and the parameters defined in the assumptions section."
      ],
      "metadata": {
        "id": "VmXpSbLrKUcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_transforms(endoscope_length=200, ENDOSCOPE_ANGLE=45,DISTANCE_FROM_CAM=2000, TUMOUR_PATREF=40  ):\n",
        "    \"\"\"\n",
        "    Returns a set of coordinate transformation matrices that convert points from one reference frame to another.\n",
        "\n",
        "    Args:\n",
        "        endoscope_length (float): Length of the endoscope in millimeters. Default is 200.\n",
        "        ENDOSCOPE_ANGLE (float): z angle at which endoscope is angled\n",
        "        DISTANCE_FROM_CAM (float): distance from camera to patient\n",
        "        TUMOUR_PATREF (float): distance from tumour to patient reference\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the following eight transformation matrices:\n",
        "        - PatRef_T_MRI: A 4x4 transformation matrix that converts points from the MRI reference frame to the patient reference frame.\n",
        "        - Cam_T_PatRef: A 4x4 transformation matrix that converts points from the patient reference frame to the camera reference frame.\n",
        "        - EndRef_T_Cam: A 4x4 transformation matrix that converts points from the camera reference frame to the endoscope reference frame. \n",
        "        - EndP_T_EndRef: A 4x4 transformation matrix that converts points from the endoscope reference frame to the endoscope tip reference frame.\n",
        "\n",
        "        and the following numpy arrays containing the homogenous coordinates of the points in the given reference frame\n",
        "        - end_ref_marker:  endRef in the pointer reference frame.\n",
        "        - end_ref_cam: endRef in the camera reference frame.\n",
        "        \n",
        "        - pat_ref_marker: patRef in the patient reference frame.\n",
        "        - pat_ref_cam: patRef in the camera reference frame.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # 1) obtaining EndRef_T_EndP\n",
        "    #print(f'endoscope length: {endoscope_length}')\n",
        "    # Creating pointer reference in the pointer reference frame.\n",
        "    end_ref_marker = create_end_ref() # marker coords\n",
        "    # Point reference to point tip: (pointer length translation in y)\n",
        "    EndP_T_EndRef = extrinsic_vecs_to_matrix(\n",
        "        [0, endoscope_length, 0, 0, 0, 0]) # create transform of all points depending on pointer's length\n",
        "    # invert to get tip to ref:\n",
        "    #EndRef_T_EndP = np.linalg.inv(EndP_T_EndRef)\n",
        "\n",
        "    # 2) obtaining Cam_T_EndRef\n",
        "    # Converting the marker points to the camera reference frame by applying a\n",
        "    # rotation of ENDOSCOPE_ANGLE degrees about the z-axis followed by a\n",
        "    # translation of DISTANCE_FROM_CAM along the z-axis of camera.\n",
        "    rotate_about_z = extrinsic_vecs_to_matrix([0, 0, 0, 0, 0, ENDOSCOPE_ANGLE])\n",
        "    translate_away_from_camera = extrinsic_vecs_to_matrix([0, 0, DISTANCE_FROM_CAM, 0, 0, 0])\n",
        "    Cam_T_EndRef = translate_away_from_camera @ rotate_about_z\n",
        "    end_ref_cam = multiply_points_by_transform(end_ref_marker, Cam_T_EndRef)\n",
        "    EndRef_T_Cam = np.linalg.inv(Cam_T_EndRef)\n",
        "\n",
        "    # 3) obtaining Cam_T_PatRef\n",
        "    # PatRef to Cam (add dist to cam to z plus x translation to right)\n",
        "    pat_ref_marker = create_pat_ref()\n",
        "    # translating to correct location \n",
        "    translate_along_x = extrinsic_vecs_to_matrix([TUMOUR_PATREF, 0, 0, 0, 0, 0])\n",
        "    Cam_T_PatRef = translate_along_x @ translate_away_from_camera\n",
        "    pat_ref_cam = multiply_points_by_transform(pat_ref_marker, Cam_T_PatRef)\n",
        "    #PatRef_T_Cam = np.linalg.inv(Cam_T_PatRef)\n",
        "\n",
        "    # 4) obtaining PatRef_T_MRI\n",
        "    PatRef_T_MRI = extrinsic_vecs_to_matrix([X_T, Y_T, Z_T, 0, 0, 0])\n",
        "    #MRI_T_PatRef = np.linalg.inv(PatRef_T_MRI)\n",
        "\n",
        "    return EndP_T_EndRef,EndRef_T_Cam,Cam_T_PatRef,PatRef_T_MRI  , end_ref_marker, end_ref_cam, pat_ref_marker, pat_ref_cam\n"
      ],
      "metadata": {
        "id": "rSDaIQm1KRsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EndP_T_EndRef,EndRef_T_Cam,Cam_T_PatRef,PatRef_T_MRI  , end_ref_marker, end_ref_cam, pat_ref_marker, pat_ref_cam= get_transforms(endoscope_length=ENDOSCOPE_LENGTH, ENDOSCOPE_ANGLE=ENDOSCOPE_ANGLE,DISTANCE_FROM_CAM=DISTANCE_FROM_CAM, TUMOUR_PATREF=TUMOUR_PATREF)\n"
      ],
      "metadata": {
        "id": "Lj1YsnfH50Rl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print('our 4 transforms:')\n",
        "\n",
        "print('PatRef_T_MRI')\n",
        "print(PatRef_T_MRI)\n",
        "\n",
        "print('Cam_T_PatRef')\n",
        "print(Cam_T_PatRef)\n",
        "\n",
        "print('EndRef_T_Cam')\n",
        "print(EndRef_T_Cam)\n",
        "\n",
        "print('EndP_T_EndRef')\n",
        "print(EndP_T_EndRef)\n",
        "\n",
        "\n",
        "print('reference frames represented in different coordinate systems')\n",
        "print('end_ref_marker')\n",
        "print(end_ref_marker)\n",
        "\n",
        "print('end_ref_cam')\n",
        "print(end_ref_cam)\n",
        "\n",
        "print('pat_ref_marker')\n",
        "print(pat_ref_marker)\n",
        "\n",
        "print('pat_ref_cam')\n",
        "print(pat_ref_cam)"
      ],
      "metadata": {
        "id": "V5xvQzIB6xzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simulations\n",
        "\n",
        "In the following section we will perform our experiments when adding noise to different parts of the setup.\n",
        "\n"
      ],
      "metadata": {
        "id": "VFdK4Mom5tfg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First let's define some necessary utility functions\n",
        "\n"
      ],
      "metadata": {
        "id": "Wj1mcw8d_kkM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def project_points(points, T, intrinsics, distortion): # target_location_in_marker_space, target_location_in_mri_space,\n",
        "    params = extrinsic_matrix_to_vecs(T)\n",
        "    # project noisy target point from camera space to image space\n",
        "    rvec = np.zeros((1,3))\n",
        "    tvec = np.zeros((1,3))\n",
        "    \n",
        "    tvec[0,0]=params[0]\n",
        "    tvec[0,1]=params[1]\n",
        "    tvec[0,2]=params[2]\n",
        "\n",
        "    rvec[0,0]=params[3]\n",
        "    rvec[0,1]=params[4]\n",
        "    rvec[0,2]=params[5]\n",
        "\n",
        "    #rvec = np.array([Cam_T_EndRef_parameters[:3]], dtype=float)\n",
        "    #tvec = np.array([Cam_T_EndRef_parameters[4:]], dtype=float)\n",
        "    transformed_point, _ = cv2.projectPoints(points[:3], rvec, tvec, intrinsics, distortion)\n",
        "    transformed_point = transformed_point.squeeze()\n",
        "    return transformed_point\n",
        "\n",
        "def add_noise_to_points(points_in, sigma):\n",
        "    \"\"\"\n",
        "    add_noise_to_points(points_in, sigma)\n",
        "    adding noise to 3D points\n",
        "\n",
        "    Args:\n",
        "        points_in: 3xN matrix of points we are adding noise to\n",
        "        sigma: standard deviation of normal distribution defining noise distribution\n",
        "\n",
        "    Returns:\n",
        "        same points but with random noise added to them\n",
        "    \"\"\"\n",
        "    \n",
        "    points_out = np.zeros((points_in.shape))\n",
        "    for r in range(points_in.shape[0]):\n",
        "        for c in range(points_in.shape[1]):\n",
        "            points_out[r][c] = points_in[r][c] + random.normalvariate(0, sigma)\n",
        "    return points_out\n",
        "\n",
        "\n",
        "def add_noise_to_params(params, sigma):\n",
        "    \"\"\"\n",
        "    add_noise_to_params(params, sigma)\n",
        "    adds noise to parameters (translation, rotation etc)\n",
        "\n",
        "    Args:\n",
        "        params: list of all parameters (translations in xyz, rotations in etc.)\n",
        "        sigma: standard deviation of normal noise to add\n",
        "\n",
        "    Returns:\n",
        "        parameters with noise added on them\n",
        "    \"\"\"\n",
        "    params_out = copy.deepcopy(params)\n",
        "    for i, p in enumerate(params):\n",
        "        params_out[i] = params[i] + random.normalvariate(0, sigma)\n",
        "    return params_out\n",
        "\n",
        "\n",
        "def calculate_euclid_dist(pointer_tip_in_mri_space,tumour_in_mri_space ):\n",
        "    \"\"\"\n",
        "    calculate_euclid_dist(pointer_tip_in_mri_space,tumour_in_mri_space )\n",
        "    calculates euclidean distance between two 3D points (euclid_dist is x^2+y^2+x^2)\n",
        "\n",
        "    Args:\n",
        "        pointer_tip_in_mri_space: 4x1 np array of where we think the tumor is\n",
        "        tumour_in_mri_space: 4x1 np array of where the tumor actually is\n",
        "\n",
        "    Returns:\n",
        "        euclidean distance between the two points\n",
        "    \"\"\"\n",
        "\n",
        "    dist =  (pointer_tip_in_mri_space[0] - tumour_in_mri_space[0]) \\\n",
        "            * (pointer_tip_in_mri_space[0] - tumour_in_mri_space[0]) \\\n",
        "            + (pointer_tip_in_mri_space[1] - tumour_in_mri_space[1]) \\\n",
        "            * (pointer_tip_in_mri_space[1] - tumour_in_mri_space[1]) \\\n",
        "            + (pointer_tip_in_mri_space[2] - tumour_in_mri_space[2]) \\\n",
        "            * (pointer_tip_in_mri_space[2] - tumour_in_mri_space[2])\n",
        "\n",
        "    return dist"
      ],
      "metadata": {
        "id": "Fvc1F6GGTm6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "the following is the main function for performing the simulation with different sources of errors"
      ],
      "metadata": {
        "id": "QyySRF3D_l3e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def simulation(EndP_T_EndRef=0, EndRef_T_Cam=0, Cam_T_PatRef=0, PatRef_T_MRI=0, end_ref_marker=0, end_ref_cam=0,\n",
        "               pat_ref_marker=0, pat_ref_cam=0,NUMBER_SAMPLES=1000,END_SIGMA=0.5 ,SIGMA_STEP=0.01,  \n",
        "               add_reg_error=False, add_tracking_noise=False, add_hand_eye_error=False, AR=False):\n",
        "    \"\"\"\n",
        "    This function simulates the tracking of a pointer using a camera-based system, and evaluates the accuracy of the\n",
        "    tracked pointer in MRI space. The function can simulate different scenarios by adding noise to the reference points\n",
        "    in camera space or adding error to the registration between patient space and MRI space. The function returns the\n",
        "    root mean squared (RMS) error between the target location of the pointer in MRI space and the tracked location.\n",
        "\n",
        "    Args:\n",
        "        The following are rigid transformations from the coordinate system on the right of T\n",
        "            to the coordinate system on the left of T\n",
        "        EndP_T_EndRef (numpy.ndarray): RT from endoscope reference to endoscope tip\n",
        "        EndRef_T_Cam (numpy.ndarray): RT from camera to endoscope reference\n",
        "        Cam_T_PatRef (numpy.ndarray): RT from patient reference to camera\n",
        "        PatRef_T_MRI (numpy.ndarray): RT from MRI to patient reference\n",
        "\n",
        "        end_ref_marker (numpy.ndarray): The position of the endoscope reference frame in marker space.\n",
        "        end_ref_cam (numpy.ndarray): The position of the endoscope reference frame in camera space.\n",
        "        pat_ref_marker (numpy.ndarray): The position of the patient reference frame in marker space.\n",
        "        pat_ref_cam (numpy.ndarray): The position of the patient reference frame in camera space.\n",
        "\n",
        "        NUMBER_SAMPLES (int): number of samples for error reproducibility\n",
        "        END_SIGMA (int): max gaussian noise standard deviation to be calculated\n",
        "        SIGMA_STEP (int): steps in which to increase gaussian noise std \n",
        "\n",
        "        add_reg_error (bool): If True, add noise to the parameters of the registration between the patient reference\n",
        "            frame and the MRI reference frame.\n",
        "        add_tracking_noise (bool): If True, add noise to the position of the reference frames in camera space.\n",
        "        add_hand_eye_error (bool): If True, add noise to hand-eye params\n",
        "        AR (bool): If True this is the AR experiment so error would be in pxls\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: The x-values of the RMS error plot.\n",
        "        numpy.ndarray: The y-values of the RMS error plot.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    x_values = []\n",
        "    y_values = []\n",
        "\n",
        "    # create a target location at the tip of the pointer in marker space\n",
        "    target_location_in_marker_space = np.zeros((4, 1))\n",
        "    target_location_in_marker_space[3, 0] = 1  # homogeous\n",
        "\n",
        "    # compute the transform from MRI to point at tip of pointer\n",
        "    #MRI_T_PntTip = MRI_T_PatRef @ PatRef_T_Cam @ Cam_T_PntRef @ PntRef_T_PntTip\n",
        "    #MRI_T_EndP = np.linalg.inv(PatRef_T_MRI) @ np.linalg.inv(Cam_T_PatRef) @ Cam_T_EndRef @  EndRef_T_EndP\n",
        "    EndP_T_MRI = EndP_T_EndRef @ EndRef_T_Cam @ Cam_T_PatRef @  PatRef_T_MRI\n",
        "\n",
        "    # transform target location to MRI space\n",
        "    #target_location_in_mri_space = MRI_T_PntTip @ target_location_in_marker_space\n",
        "    target_location_in_mri_space = np.linalg.inv(EndP_T_MRI) @ target_location_in_marker_space\n",
        "\n",
        "    if AR:\n",
        "        T = np.linalg.inv(EndP_T_EndRef @ EndRef_T_Cam)\n",
        "        target_location_in_image_coordinates = project_points(target_location_in_mri_space[:3], T, intrinsics, distortion)\n",
        "            \n",
        "    ###### CHANGE ALL PatRef_T_Cam AND MRI_T_PatRef\n",
        "    #MRI_T_PatRef_original = copy.deepcopy(MRI_T_PatRef)\n",
        "    PatRef_T_MRI_original = copy.deepcopy(PatRef_T_MRI)\n",
        "    EndP_T_EndRef_original = copy.deepcopy(EndP_T_EndRef)\n",
        "\n",
        "    #### -------- CHECK BELOW\n",
        "    for sigma in np.arange(0, END_SIGMA + SIGMA_STEP, SIGMA_STEP):\n",
        "        # sigma = float(sigma_counter) / float(100)\n",
        "        # print(sigma)\n",
        "        rms = 0\n",
        "        for i in range(NUMBER_SAMPLES):\n",
        "\n",
        "            if add_tracking_noise:\n",
        "                # add tracking noise to the reference points in camera space\n",
        "                noisy_end_ref_cam = add_noise_to_points(end_ref_cam[:, 0:3], sigma)\n",
        "                # compute transforms with the noisy reference points (from references to camera)\n",
        "                R, t, FRE = pro.orthogonal_procrustes(noisy_end_ref_cam[:, 0:3], end_ref_marker[:, 0:3])\n",
        "                Cam_T_EndRef = mu.construct_rigid_transformation(R, t)\n",
        "                EndRef_T_Cam = np.linalg.inv(Cam_T_EndRef)\n",
        "\n",
        "                # same for patient reference\n",
        "                noisy_pat_ref_cam = add_noise_to_points(pat_ref_cam[:, 0:3], sigma)\n",
        "                R, t, FRE = pro.orthogonal_procrustes(pat_ref_marker[:, 0:3], noisy_pat_ref_cam[:, 0:3])\n",
        "                PatRef_T_Cam = mu.construct_rigid_transformation(R, t)\n",
        "                Cam_T_PatRef = np.linalg.inv(PatRef_T_Cam)\n",
        "\n",
        "            if add_reg_error:\n",
        "                # Here we add noise onto the PatRef_T_MRI_parameters, and reconstruct a new registration\n",
        "                PatRef_T_MRI_parameters = extrinsic_matrix_to_vecs(PatRef_T_MRI_original)\n",
        "                PatRef_T_MRI_noisy_parameters = add_noise_to_params(PatRef_T_MRI_parameters, sigma)\n",
        "                PatRef_T_MRI = extrinsic_vecs_to_matrix(PatRef_T_MRI_noisy_parameters)\n",
        "\n",
        "            if add_hand_eye_error:\n",
        "                # adding hand eye noise to parameters then reconstruct noisy transformation\n",
        "                Hand_T_Eye_parameters = extrinsic_matrix_to_vecs(EndP_T_EndRef_original)\n",
        "                noisy_hand_eye_params = add_noise_to_params(Hand_T_Eye_parameters, sigma)\n",
        "                EndP_T_EndRef = extrinsic_vecs_to_matrix(noisy_hand_eye_params)\n",
        "\n",
        "\n",
        "            # use noisy transforms to get a target location from camera space to MRI space.            \n",
        "            EndP_T_MRI_noisy = EndP_T_EndRef @ EndRef_T_Cam @ Cam_T_PatRef @  PatRef_T_MRI\n",
        "            target_location_in_mri_space_noisy = np.linalg.inv(EndP_T_MRI_noisy) @ target_location_in_marker_space\n",
        "\n",
        "            # calculate euclidean distance between noisy transformed point and target location (in MRI space or image space depending on simulation)\n",
        "            if AR:\n",
        "                \n",
        "                T_noisy = np.linalg.inv(EndP_T_EndRef @ EndRef_T_Cam)\n",
        "                transformed_point_in_image_space_noisy = project_points(target_location_in_mri_space_noisy[:3], T_noisy, intrinsics, distortion)\n",
        "\n",
        "                euclid_dist =  (transformed_point_in_image_space_noisy[0] - target_location_in_image_coordinates[0]) \\\n",
        "                        * (transformed_point_in_image_space_noisy[0] - target_location_in_image_coordinates[0]) \\\n",
        "                        + (transformed_point_in_image_space_noisy[1] - target_location_in_image_coordinates[1]) \\\n",
        "                        * (transformed_point_in_image_space_noisy[1] - target_location_in_image_coordinates[1]) \n",
        "\n",
        "            else:\n",
        "                euclid_dist = calculate_euclid_dist(target_location_in_mri_space_noisy, target_location_in_mri_space)\n",
        "            \n",
        "            rms = rms + float(euclid_dist)\n",
        "\n",
        "        # calculating root mean square\n",
        "        rms = rms / float(NUMBER_SAMPLES)\n",
        "        rms = np.sqrt(rms)\n",
        "\n",
        "        x_values.append(sigma)\n",
        "        y_values.append(rms)\n",
        "\n",
        "    return np.array(x_values), np.array(y_values)"
      ],
      "metadata": {
        "id": "rEw0tIhv7PWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following is simply for visualising the results\n",
        "\n"
      ],
      "metadata": {
        "id": "8NP82nx7_B5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_TRE_results(x, y, title=''):\n",
        "    plt.figure()\n",
        "    plt.title(title)\n",
        "    plt.plot(x, y, 'r', label='TRE (mm)', marker='o')\n",
        "    plt.legend(loc='upper left')\n",
        "    plt.xlabel('sigma ')\n",
        "    plt.ylabel('TRE (mm)')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "xfJUcRsu_BZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "and the intrinsics and distortion parameters that will be used to project the points from 3D to 2D. These parameters were obtained by calibrating the endoscope with Zhang's camera calibration algorithm "
      ],
      "metadata": {
        "id": "5mQiEHgg_G1n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "intrinsics = np.array([\n",
        "    [664.63297660, 0.00000000, 931.53151205],\n",
        "    [0.00000000, 663.83211807, 520.64004697],\n",
        "    [0.00000000, 0.00000000, 1.00000000]\n",
        "])\n",
        "\n",
        "distortion = np.array([\n",
        "    -0.40929449, 0.21631278, 0.00001112, 0.00127120, -0.07205712\n",
        "])"
      ],
      "metadata": {
        "id": "FZJcB3Z0AAr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experiment 1: Tracking error\n",
        "\n",
        "Here we add random noise to the location of the tracking markers (pointer and patient ref)\n",
        "\n"
      ],
      "metadata": {
        "id": "6mNW2xjCbypD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tracking_x_values, tracking_y_values = simulation(EndP_T_EndRef=EndP_T_EndRef, \n",
        "                  EndRef_T_Cam=EndRef_T_Cam, \n",
        "                  Cam_T_PatRef=Cam_T_PatRef, \n",
        "                  PatRef_T_MRI=PatRef_T_MRI, \n",
        "\n",
        "                  end_ref_marker=end_ref_marker, \n",
        "                  end_ref_cam=end_ref_cam,\n",
        "                  pat_ref_marker=pat_ref_marker, \n",
        "                  pat_ref_cam=pat_ref_cam,\n",
        "                  \n",
        "                  NUMBER_SAMPLES=NUMBER_SAMPLES,\n",
        "                  END_SIGMA=END_SIGMA ,\n",
        "                  SIGMA_STEP=SIGMA_STEP,  \n",
        "\n",
        "                  add_reg_error=False, \n",
        "                  add_tracking_noise=True, \n",
        "                  add_hand_eye_error=False, \n",
        "                  AR=False)"
      ],
      "metadata": {
        "id": "5KCsK-X5W-oN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_TRE_results(tracking_x_values,tracking_y_values,title='tracking error')\n"
      ],
      "metadata": {
        "id": "vocyPT57YXSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experiment 2: Registration error\n",
        "\n",
        "Registration error between the patient and the MRI scan, similar to that of pointer simulation"
      ],
      "metadata": {
        "id": "eFR_-UH3fJgY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "registration_x_values, registration_y_values = simulation(EndP_T_EndRef=EndP_T_EndRef, \n",
        "                  EndRef_T_Cam=EndRef_T_Cam, \n",
        "                  Cam_T_PatRef=Cam_T_PatRef, \n",
        "                  PatRef_T_MRI=PatRef_T_MRI, \n",
        "\n",
        "                  end_ref_marker=end_ref_marker, \n",
        "                  end_ref_cam=end_ref_cam,\n",
        "                  pat_ref_marker=pat_ref_marker, \n",
        "                  pat_ref_cam=pat_ref_cam,\n",
        "                  \n",
        "                  NUMBER_SAMPLES=NUMBER_SAMPLES,\n",
        "                  END_SIGMA=END_SIGMA,\n",
        "                  SIGMA_STEP=SIGMA_STEP,  \n",
        "\n",
        "                  add_reg_error=True, \n",
        "                  add_tracking_noise=False, \n",
        "                  add_hand_eye_error=False, \n",
        "                  AR=False)"
      ],
      "metadata": {
        "id": "OclutDKAfNJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_TRE_results(registration_x_values, registration_y_values,title='registration error')\n"
      ],
      "metadata": {
        "id": "Z91yl6DifROh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment 3: Hand eye error\n",
        "\n",
        "Adding noise to the transform between the endoscope reference and the camera of the endoscope. This is typically called hand-eye transform, and can be obtained by hand-eye calibration."
      ],
      "metadata": {
        "id": "mReKwobMfc_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hand_eye_x_values, hand_eye_y_values = simulation(EndP_T_EndRef=EndP_T_EndRef, \n",
        "                  EndRef_T_Cam=EndRef_T_Cam, \n",
        "                  Cam_T_PatRef=Cam_T_PatRef, \n",
        "                  PatRef_T_MRI=PatRef_T_MRI, \n",
        "\n",
        "                  end_ref_marker=end_ref_marker, \n",
        "                  end_ref_cam=end_ref_cam,\n",
        "                  pat_ref_marker=pat_ref_marker, \n",
        "                  pat_ref_cam=pat_ref_cam,\n",
        "                  \n",
        "                  NUMBER_SAMPLES=NUMBER_SAMPLES,\n",
        "                  END_SIGMA=END_SIGMA,\n",
        "                  SIGMA_STEP=SIGMA_STEP,  \n",
        "\n",
        "                  add_reg_error=False, \n",
        "                  add_tracking_noise=False, \n",
        "                  add_hand_eye_error=True, \n",
        "                  AR=False)"
      ],
      "metadata": {
        "id": "qGtKN1J_feZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_TRE_results(hand_eye_x_values, hand_eye_y_values,title='hand eye error')\n"
      ],
      "metadata": {
        "id": "2GhwSuFnfrMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experiment 4: AR \n",
        "\n",
        "Here we investigate what the error will be like in an AR system, where we project the points to 2D. \n",
        "\n",
        "We add all sources of error before projecting the points and compare the projected point using the noisy transforms and the original points. \n",
        "\n",
        "The error will be in pixels as once projected, the units are in image coordinates."
      ],
      "metadata": {
        "id": "PtEO4AUFfy_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AR_x_values, AR_y_values = simulation(EndP_T_EndRef=EndP_T_EndRef, \n",
        "                  EndRef_T_Cam=EndRef_T_Cam, \n",
        "                  Cam_T_PatRef=Cam_T_PatRef, \n",
        "                  PatRef_T_MRI=PatRef_T_MRI, \n",
        "\n",
        "                  end_ref_marker=end_ref_marker, \n",
        "                  end_ref_cam=end_ref_cam,\n",
        "                  pat_ref_marker=pat_ref_marker, \n",
        "                  pat_ref_cam=pat_ref_cam,\n",
        "                  \n",
        "                  NUMBER_SAMPLES=NUMBER_SAMPLES,\n",
        "                  END_SIGMA=END_SIGMA ,\n",
        "                  SIGMA_STEP=SIGMA_STEP,  \n",
        "\n",
        "                  add_reg_error=True, \n",
        "                  add_tracking_noise=True, \n",
        "                  add_hand_eye_error=True, \n",
        "                  AR=True)"
      ],
      "metadata": {
        "id": "MmTOOUe4f0Km"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_TRE_results(AR_x_values,AR_y_values,title='AR')\n"
      ],
      "metadata": {
        "id": "DAe6CI2igNh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Total error in mm"
      ],
      "metadata": {
        "id": "VsUHYy-M-Kb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_x_values, total_y_values = simulation(EndP_T_EndRef=EndP_T_EndRef, \n",
        "                  EndRef_T_Cam=EndRef_T_Cam, \n",
        "                  Cam_T_PatRef=Cam_T_PatRef, \n",
        "                  PatRef_T_MRI=PatRef_T_MRI, \n",
        "\n",
        "                  end_ref_marker=end_ref_marker, \n",
        "                  end_ref_cam=end_ref_cam,\n",
        "                  pat_ref_marker=pat_ref_marker, \n",
        "                  pat_ref_cam=pat_ref_cam,\n",
        "                  \n",
        "                  NUMBER_SAMPLES=NUMBER_SAMPLES,\n",
        "                  END_SIGMA=END_SIGMA ,\n",
        "                  SIGMA_STEP=SIGMA_STEP,  \n",
        "\n",
        "                  add_reg_error=True, \n",
        "                  add_tracking_noise=True, \n",
        "                  add_hand_eye_error=True, \n",
        "                  AR=False)"
      ],
      "metadata": {
        "id": "ZfkUodix-HwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_TRE_results(total_x_values,total_y_values,title='total')\n"
      ],
      "metadata": {
        "id": "S9NnXfM2-Ub5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary Results"
      ],
      "metadata": {
        "id": "1gVZvIF195Li"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('tracking error')\n",
        "print(tracking_y_values[tracking_x_values == 0.2])"
      ],
      "metadata": {
        "id": "g16I9H4v96pi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('registration error')\n",
        "print(registration_y_values[registration_x_values == 0.2])"
      ],
      "metadata": {
        "id": "BmvMy6IK-D_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('hand eye error')\n",
        "print(hand_eye_y_values[hand_eye_x_values == 0.2])"
      ],
      "metadata": {
        "id": "NTsl9ELZ-b6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('AR error')\n",
        "print(AR_y_values[AR_x_values == 0.2])"
      ],
      "metadata": {
        "id": "cUYeBlFOJ5sT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('total error')\n",
        "print(total_y_values[total_x_values == 0.2])"
      ],
      "metadata": {
        "id": "KOJ6kswX-Ehz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv \n",
        "import os\n",
        "\n",
        "header = ['group','error', 'sigma','unit','TRE']\n",
        "\n",
        "data_endoscope = [\n",
        "    ['endoscope','tracking', '0.20','mm',  float(tracking_y_values[tracking_x_values==0.2])],\n",
        "    ['endoscope', 'registration', '0.20', 'mm', float(registration_y_values[registration_x_values==0.2])],\n",
        "    ['endoscope', 'hand eye', '0.20', 'mm', float(hand_eye_y_values[hand_eye_x_values==0.2])],\n",
        "    ['endoscope', 'AR', '0.20', 'px', float(AR_y_values[AR_x_values==0.2][0])]\n",
        "]\n",
        "\n",
        "#os.mkdir('results')\n",
        "with open(f'./endoscope.csv', 'w') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(header)\n",
        "    writer.writerows(data_endoscope)"
      ],
      "metadata": {
        "id": "lAvb3Mg32qP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's ask the question- what is the largest tracking accuracy we can use (sigma) that will achieve an error of 1mm:"
      ],
      "metadata": {
        "id": "8zX5slJaD8UA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sigma_1mm = total_x_values[total_y_values<1].max()\n",
        "\n",
        "print(f'the most accurate NDI IR camera has a tracking accuracy of 0.12 mm.')\n",
        "print(f'In order to achieve a TRE of below 1 mm, we would require a camera with {sigma_1mm} mm accuracy')"
      ],
      "metadata": {
        "id": "_k4eXo-1DUWL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}